## 通用测试用例八要素

![img](https://img-blog.csdnimg.cn/img_convert/fde5e8955b1c0d7366ea094708cd1fc6.png)　　<img src="https://img-blog.csdnimg.cn/da3dfbaa6b9441589dd178540d3552ab.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASVTlpbPlrak=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom: 80%;" />

**1、用例编号；**

> 一般是数字和字符组合成的字符串，可以包括（下划线、单词缩写、数字等等），但是需要注意的是，尽量不要写汉语拼音，因为拼音的意义可能有好几种，有可能会导致乱码； 
>
> 用例编号具有唯一性和易识别性。（ 比如说我们唯一标识一个人：中国-上海市-xx区xx号-xx楼--xx室-xxx.这样标识的话就具有唯一性了。)

　　不同阶段的测试用例的用例编号有不同的规则：
　　（1）系统测试用例：产品编号-ST-系统测试项名-系统测试子项名-XXX
　　（2）集成测试用例：产品编号-IT-系统测试项名-系统测试子项名-XXX
　　（3）单元测试用例：产品编号-UT-系统测试项名-系统测试子项名-XXX
　　**其中产品编号也叫项目标识，每个公司都有若干不同的项目或者产品，如何来区分它们呢？这就需要有产品编号了，每个公司都有自己的一套定义产品编号的规则，并且每个现有产品的编号已经制定好了，直接拿过来用就可以了。
　　**产品编号后的ST、IT、UT分别对应系统测试阶段、集成测试阶段、单元测试阶段。实际工作中有些公司会将产品编号以及测试阶段省略。
　　**测试阶段后面就是测试项目名了，对应的是较大较系统的测试点。
　　**测试项目名后面就是测试子项目名，有些测试是没有子项目名的，只有当测试项力度比较大的时候才会有成都市子项 （比如说：我们要测试用户能否成功登录这个功能，那我们就可以分为很多个子项，qq登录、邮箱登录等等）。
　	测试子项名后面就是具体的用例编号了，可以是数字：01、001、002等等。



　　**2、测试项目；**

（1）系统测试用例：对应一个功能点（功能测试）、性能指标（性能测试）、界面中控件（GUI测试）等等。
（2）集成测试用例：对应集成后的模块功能或者接口功能。
（3）单元测试用例：对应函数名。 



　　**3、测试标题；**

　　**4、重要级别；**

用例的重要级别一般分成三个级别：高、中、低。
高级别：对应保证系统基本功能、核心业务、重要特性、实际使用频率比较高的用例；
中级别：对应重要程度介于高和低之间的测试用例；
低级别：对应实际使用频率不高，对系统业务功能影响比较大的模块或功能的测试用例。



　　**5、预置条件；**

> 　 测试用例在执行前需要满足一些前提条件，否则测试用例是无法执行的，这些前提条件就是预置条件。

　　预置条件分为两种情况：
　　（1）环境的设置。
　　例如：测试word打开文件的功能，预置条件就是：需要提前准备被打开的文件；
　　例如：登录成功的预置条件就是：该用户名已经注册过了。
　　例如：购买商品成功的预置条件就是：后台已经配置好商品、发货区域、以及支付方式了。
　　（2）先要运行的其他用例，有些操作系统会比较复杂，如果都是从最开始的操作开始会导致用例写起来比较麻烦，这样可以在预置条件中设定要先运行的测试用例，后面的用例只需要写后续的操作就可以了。
　　例如：对自动取款机进行测试，有针对的输入账户信息的测试，有对输入取钱金额的测试，后者的预置条件就可以写成输入正确账户信息的测试用例。
　　注：具体预置条件的设置不同的公司会有自己的规定，比如有的公司是不允许第二种情况出现的。



　　**6、测试输入；**

测试输入是用于运行测试用例的具体数据或值。这些输入数据用于模拟不同的用户操作和场景。

- **示例**：

  - 用户名和密码用于登录测试。
  - 搜索关键词用于搜索功能测试。

- **重要性**：

  - 它们是产生预期结果的“触发器”。

  - 用于验证应用程序如何处理不同类型和范围的数据。

    

　　**7、操作步骤；**

明确描述测试执行过程中具体的操作步骤，以方便测试执行人员可以根据该操作步骤完成测试用例执行。

- **示例**：

  1. 打开应用程序。
  2. 在用户名字段中输入预定义的用户名。
  3. 在密码字段中输入预定义的密码。
  4. 点击“登录”按钮。

- **重要性**：

  - 提供了一种结构化的方式来执行测试，确保测试的一致性和可重复性。

  - 有助于准确地复现缺陷和问题。

    

　　**8、预期输出；**

> （1）界面显示：在操作步骤完成之后，界面会有显示；比如说我们测试用户登录功能，界面可能会显示登录成功或者登录失败。
>
> （2）数据库的变化：在操作步骤完成之后，数据库中的记录会发生相应的变化，比如删除功能的测试，点击删除后，数据库中该记录会被删除。
>
> （3）相关信息的变化：在操作步骤执行完成后，一些和被测对象相关的信息会发生变化，比如：注销功能的测试，点击注销后，以前能访问的页面将无法再访问。 



## 测试要点

<img src="https://img-blog.csdn.net/20180505154820871" alt="img" style="zoom:80%;" />



## 软件测试类别

![img](https://img-blog.csdnimg.cn/20210919103511372.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA57qi55uu6aaZ6Jaw,size_20,color_FFFFFF,t_70,g_se,x_16)





### 白盒测试（White-box Testing）

白盒测试又叫结构测试或透明盒测试，主要针对软件内部结构、工作流程和功能进行测试。测试者需要了解被测试软件的内部结构和工作原理。白盒测试主要包括以下几种：

1. **单元测试（Unit Testing）**: 测试单个程序、子程序、模块或对象。

2. **路径测试（Path Testing）**: 验证所有代码路径都被正确执行。

3. **数据流测试（Data Flow Testing）**: 测试程序变量的初始化和修改。

4. **循环测试（Loop Testing）**: 针对软件中的所有循环结构进行测试。

5. **条件测试（Condition Testing）**: 验证决策语句**（if、switch等）。**

6. **代码覆盖测试（Code Coverage）**: 确保代码中的每一行、每一个分支都被执行过。

7. **静态分析（Static Analysis）**: 不执行代码，**通过代码检查或使用静态分析工具进行测试。**

8. **集成测试（Integration Testing）**: 在这个上下文中，**集成测试**通常针对模块间的接口进行。

   

### 黑盒测试（Black-box Testing）

黑盒测试又称为功能测试，它是在不了解内部结构和工作原理的情况下，对软件外部行为进行测试。主要包括以下几种：

1. **功能测试（Functional Testing）**: 测试软件所有功能是否按照需求规格书工作。

2. **边界值测试（Boundary Testing）**: 测试输入或输出数据边界条件。

3. **等价类划分（Equivalence Partitioning）**: 将输入数据分为几个**等价类别**，然后用这几个类别进行测试。

   等价类划分是一种测试设计技术，其中输入域被分为几个等价类。一个等价类中的所有值都应该具有相同的特性，并被预期产生相同的结果。通常从每个等价类中选取一个或几个代表性的值进行测试。

   例子：

   假设有一个函数，该函数接受年龄（1-100）作为输入并返回是否成年（>= 18）。这里有两个等价类：

   1. 1-17（未成年）
   2. 18-100（成年）

   选择每个等价类中的一个或两个值进行测试即可。

   优缺点：

   - **优点**：减少了测试用例的数量，同时保持了高覆盖率。
   - **缺点**：可能会错过一些边界条件。

4. **因果图**

5. **错误推测法：**

   错误推测法是一种经验性的测试方法，它依赖于测试人员或开发人员对系统可能出现错误的直觉和经验。

   例子：

   在一个电子商务应用中，对于信用卡号的验证，除了正常的输入检查外，测试人员可能会尝试一些常见的错误情况，如使用过期的卡、无效的卡号等。

   优缺点：

   - **优点**：能够找出那些正规测试方法可能忽视的问题。

   - **缺点**：完全依赖于个人经验和直觉，不系统化。

     

6. **决策表测试（Decision Table Testing）**: 用表格的方式来表示复杂业务规则，并据此进行测试。

   决策表测试是一种表格形式的测试设计技术，**用于处理多个相关的输入和输出条件。这种方法特别适用于复杂的业务逻辑和决策过程。**

   例子：

   在一个贷款批准流程中，输入可能包括“年收入”，“信用评分”，“拥有财产”等，输出则是“批准”或“拒绝”。通过决策表，可以列出所有可能的输入组合和相应的输出。

   优缺点：

   - **优点**：结构清晰，易于理解和维护。
   - **缺点**：对于具有大量输入/输出和决策路径的系统，决策表可能变得很复杂。

7. **状态转换测试（State Transition Testing）**: 测试从一个状态转换到另一个状态是否成功。

8. **压力测试（Stress Testing）**: 测试软件在极端条件（如资源不足、高并发）下的表现。

9. **性能测试（Performance Testing）**: 测量软件某些特定操作的响应时间或吞吐量。

10. **兼容性测试（Compatibility Testing）**: 测试软件在不同环境（如不同的浏览器、操作系统、硬件等）中的运行情况。

11. **接受测试（Acceptance Testing）**: 最终用户或客户进行的测试，以确定软件是否能被接受。



  **黑盒测试主要的方法有：等价类划分法、边界值分析法、错误推测法、因果图法、决策表法、场景法等。** 

  **白盒测试的主要方法有：语句覆盖、判定覆盖、条件覆盖、判定/条件覆盖、条件组合覆盖、路径覆盖等。** 

<img src="C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020135003126.png" alt="image-20231020135003126" style="zoom: 50%;" />

**负载测试**：是通过逐步增加系统负载，测试系统性能的变化，并在**满足最终确定性能指标的情况下**，系统所能承受的**最大负载量**的测试

**压力测试**：逐步增加系统负载，测试系统性能的变化，并最终确定在什么负载下系统性能**处于失效状态**，并以此来获得系统能提供的**最大服务级别的测试**



#### 冒烟测试

**冒烟测试（Smoke Testing），也有时称为“构建验证测试”（Build Verification Testing）或“健康检查测试”（Health Check Testing），**是软件发布的早期测试中一个非常重要的部分。其主要目的是验证软件构建的基本功能是否可以正常工作，以便决定是否继续进行更深入的测试。

冒烟测试通常在软件构建完成后的初步阶段进行，就像是对软件进行一次快速的健康检查。这个过程通常包括以下几个关键步骤或特点：

- **快速执行**：冒烟测试是一系列快速的测试，旨在检查软件的核心功能是否有严重问题。
- **基本功能**：它集中于软件的基本操作和主要功能，确保没有“阻断性”（blocker）缺陷，即那些会影响软件基本功能的重大错误。
- **非详尽测试**：冒烟测试不是详尽的测试，它只验证软件的关键功能是否足够稳定以便进行进一步的测试。
- **自动化或手动**：冒烟测试可以手动进行，也可以通过自动化测试工具实现，尤其在持续集成的环境中。
- **决策依据**：如果冒烟测试失败，通常意味着构建有重大缺陷，需要返回开发团队修复后再进行进一步测试。
- **常规实践**：在敏捷开发和持续部署的环境中，冒烟测试通常是每次构建后自动执行的，以快速验证新版本的稳定性。

冒烟测试的名称来源于电子工程领域，当硬件首次通电时，如果没有冒烟，那么硬件就被认为是基本合格的。同理，在软件领域，如果一次构建通过了冒烟测试，那么它就可以认为是准备好了进一步的测试工作。



#### 专项测试

专项测试是针对软件或系统中特定功能或特性的详细测试。这类测试专注于一个特定的测试领域，旨在深入检查和验证该领域内的所有方面。专项测试通常在软件开发的某个阶段进行，尤其是在基本功能测试完成后，以确保软件的特定部分满足其设计要求和性能标准。



#### 协议测试

协议测试是指验证和确保通信协议（如 TCP/IP, HTTP, FTP 等）的实现符合其规范和标准的过程。这类测试专注于网络协议、通信接口、数据传输和报文格式等方面，确保系统或应用程序能够正确、有效地进行数据交换和通信。

- #### 协议测试的关键要素


1. **规范符合性（Conformance Testing）**：
   - 确保实现正确地遵循了协议的规范。
   - 检查协议的各个功能和操作是否按照标准执行。

2. **互操作性（Interoperability Testing）**：
   - 测试不同设备或应用程序之间的兼容性，确保它们能够顺利交换信息和共同工作。
- 这通常包括在多种配置、网络环境和不同厂商的设备上测试。
  
3. **性能测试（Performance Testing）**：
   - 测试协议在不同网络条件下的性能表现，如延迟、带宽利用率、吞吐量和错误恢复能力。
- 模拟高负载和高压情况以评估性能极限。
  
4. **安全性测试（Security Testing）**：
   
   - 验证协议实现的安全特性，如认证、加密、数据完整性和抵抗攻击的能力。
   
     

- #### **协议测试的方法和工具**

- **模拟器和测试环境**：使用专门的软件模拟器和测试环境来创建各种网络条件和场景。

- **流量生成和分析**：生成网络流量，并分析数据包以确保它们符合协议规范。

- **自动化测试工具**：使用自动化工具执行重复的测试案例，提高测试的效率和覆盖率。

  

**代码示例**

在软件开发中，协议测试通常涉及编写单元测试和集成测试来验证协议的实现。例如，如果你正在测试一个 HTTP 客户端的实现，你可能会编写如下的测试用例：

```javascript
const httpClient = require('your-http-client');
const assert = require('assert');

describe('HTTP Client Protocol Tests', () => {
    it('should handle GET requests', async () => {
        const response = await httpClient.get('http://example.com');
        assert.equal(response.statusCode, 200);
        // 更多的断言来检查响应头、响应体等
    });

    it('should handle POST requests with payload', async () => {
        const data = { key: 'value' };
        const response = await httpClient.post('http://example.com', data);
        assert.equal(response.statusCode, 200);
        // 检查发送的数据和接收到的响应
    });

    // 更多测试用例...
});
```

协议测试是确保数据通信准确无误的关键步骤，特别是在构建需要网络通信的软件和硬件产品时。它不仅关注于规范的符合性，还涵盖性能、安全性和互操作性等方面。通过有效的协议测试，可以保证产品在真实世界的网络环境中可靠地运行。



#### 负载测试（Load Testing）

1. **目的**: 负载测试的主要目的是**确定系统在正常和预期的负载下的性能。**
2. **范围**: 负载测试通常会模拟多个用户同时访问或使用应用，但这些负载都是预先设定并且在系统承受能力之内的。
3. **指标**: 主要关注的性能指标包括**响应时间、吞吐量、系统资源（CPU、内存、磁盘、网络等**）的使用情况。
4. **测试场景**: 通常模拟真实世界的正常业务操作和用户行为。



#### 压力测试（Stress Testing）

1. **目的**: 压力测试的目标是找出系统的极限性能和确定系统在极端负载下的稳定性。
2. **范围**: 这种测试涉及将系统推向其极限，经常超过系统的预期或设计能力，以查看它会如何失败和恢复。
3. **指标**: 主要关注系统的**故障点、可恢复性**，以及在**高负载或资源不足的情况下是否会导致系统崩溃或数据丢失。**
4. **测试场景**: 通常涉及极端情况，如数据库突然不可用、网络突然断开或者非常大量的用户请求。



#### 稳定性测试（Stability Testing）

稳定性测试是一种软件测试类型，其主要目的是确保软件或系统在**长时间运行或在复杂负载下依然保持稳定和可靠的性能**。这通常涉及在多种不同的环境和条件下，对软件进行长时间或持续不断的测试。

**主要特点：**

1. **持续运行**: 测试可能需要持续数小时、数天或更长时间，以模拟实际运行环境。
2. **复杂负载**: 除了正常操作外，还可能包括各种边缘案例和复杂的用户交互。
3. **多种环境**: 可能需要在**不同的操作系统、硬件和网络配置下进行测试。**

**主要目标：**

- **性能维持**: 确保在长时间运行后，**性能（如响应时间、吞吐量等）没有明显下降。**
- **资源管理**: 观察**系统资源（如CPU、内存、磁盘等）的使用情况，确保没有内存泄漏、资源泄漏或其他稳定性问题。**
- **错误处理**: 验证系统能够有效地处理错误和异常情况，并能够在发生故障后安全地恢复。
- **数据完整性**: 在各种操作和故障情况下，数据应保持完整和一致。



### 接口测试

#### 接口文档分析

接口文档一般是由后端开发提供，可以是在线的**swagger**也可以是**word**。

![img](https://pic2.zhimg.com/80/v2-f7e9e8a489498c0c878cb83d9d885df9_1440w.webp)



####  **接口信息五要素**

**1）接口地址url：**

http-请求协议，api.lemonban.com-域名或ip，8765-端口号，/futureloan/member/register-资源路径

**2）请求方法：**

看开发定义的请求方法是什么，测试就对应用什么方法。restful风格中常见的请求方法为post、get、put、patch、delete等

**3）请求头：**

发送请求到服务器，包含的头部信息。常见的content-type。

**4）请求体：**

发送请求到服务器，具体传递的数据。例如要完成注册接口的调用，请求体包含手机号mobile_phone、密码pwd、用户名reg_name、验证码verification_code。

**5）响应内容：**

接口文档中描述的响应内容，与接口测试的实际结果做比较，可以判断当前接口是否通过。响应内容包含：**响应码-http状态码、响应头、响应体。**



#### 接口用例设计

接口用例设计跟功能测试思维相通，需要：

1）清楚项目业务

 2）运用用例设计8大方法：**等价类、边界值**、场景法、因果图、判定表、正交试验法、状态迁移法、错误推测法。

**1. 等价类划分（Equivalence Class Partitioning）**

**目的**：**简化测试用例的数量，同时保持测试的有效性。**

**步骤**：

1. 识别输入参数和它们的值范围。
2. 划分等价类：有效等价类和无效等价类。
3. 为每个等价类设计一个或几个测试用例。

**例子**：测试年龄输入字段，接受18-60岁。有效等价类：[18, 60]，无效等价类：小于18和大于60。

**2. 边界值分析（Boundary Value Analysis）**

**目的**：**测试输入或输出边界条件。**

**步骤**：

1. 确定输入或输出边界。
2. 设计测试用例，包括边界值。

**例子**：使用年龄18、19、59、60作为测试用例。

**3. 场景法（Scenario Testing）**

**目的**：**模拟真实世界的情况。**

**步骤**：

1. 理解用户如何使用系统。
2. 根据实际使用场景设计测试用例。

**4. 因果图（Cause-Effect Graphing）**

**目的**：**识别输入和输出之间的依赖关系。**

**步骤**：

1. 列出所有可能的输入条件（因）和输出结果（果）。
2. 绘制因果图。
3. 生成测试用例。

**5. 判定表（Decision Table）**

**目的**：处理复杂的业务规则。

**步骤**：

1. 确定输入和输出变量。
2. 构建判定表。
3. 根据判定表生成测试用例。

**6. 正交试验法（Orthogonal Array Testing）**

**目的**：在多变量系统中找出最优的测试组合。

**步骤**：

1. 确定要测试的变量和它们的可能值。
2. 使用正交数组来确定测试组合。

**7. 状态迁移法（State Transition Testing）**

**目的**：测试系统在不同状态间的行为。

**步骤**：

1. 确定系统的各种状态。
2. 确定从一个状态到另一个状态的转换。
3. 设计测试用例以覆盖所有可能的状态转换。

**8. 错误推测法（Error Guessing）**

**目的**：基于经验和直觉来设计测试用例。

**步骤**：

1. 根据之前的缺陷或常见的错误模式来推测可能的错误。

2. 设计针对这些错误的测试用例。

   

以下是接口用例模板参考：

![img](https://pic2.zhimg.com/80/v2-71755a986c543385af8e1aac3897d7d9_1440w.webp)



#### 发现bug、定位、提交并跟踪

怎么判断是否是bug呢？

**1）接口测试中响应结果错误，返回了错误的code码、msg信息：**

- 判断请求：请求地址、方式、请求头、请求正文是否正确，如果不正确则修改对应请求信息再做发送；如果正确，则说明是服务器端问题
- 进一步查看服务器日志、数据库信息，并整理信息提交bug

**2）接口测试中响应结果，code码、msg正确，但返回的data数据不正确：**

- 查看数据库数据正确完整性，并结合服务器日志，整理信息提交bug

**3）接口测试中响应结果正确，但若是增删改业务操作：**

- 需进一步确认到数据库层面，**数据增删改的正确性**

**4）考虑安全性：一般接口对请求会做出一些限制,比如请求次数、请求频率限制；涉及敏感信息是否加密**



![image-20231020141624928](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020141624928.png)

**α测试**是指软件开发公司组织内部人员模拟各类用户对即将面市软件产品（称为α版本）进行测试，试图发现错误并修正。α测试的关键在于尽可能逼真地模拟实际运行环境和用户对软件产品的操作并尽最大努力涵盖所有可能的 用户操作方式。经过α测试调整的软件产品称为β版本。 

**β测试**是由软件的多个用户在实际使用环境下进行的测试，这些用户返回有关错误信息给开发者。测试时，开发者通常不在测试现场。因而，β测试是在开发者无法控制的环境下进行的软件现场应用。在β测试中，由用户记下遇到的所有问题，包括真实的以及主观认定的，定期向开发者报告。β测试主要衡量产品的FLURPS，着重于产品的支持性，包括文档，客户培训和支持产品生产能力。 只有当α测试达到一定的可靠程度时，才能开始β测试。它处在整个测试的最后阶段。同时，产品的所有手册文本也应该在此阶段完全定稿。



### 业务测试（Business Testing）

业务测试（Business Testing）通常指的是在软件测试过程中专注于验证软件的业务逻辑是否符合业务要求和预期。这种测试不仅仅关注软件本身的技术细节，而更多地关注软件是否能满足商业目标和用户需求。业务测试通常包括以下几个方面：

**1. 验证业务流程**

- **目的**：确保软件能够正确地执行各种业务流程和操作。
- **例子**：在电子商务应用中测试购物车功能，包括添加商品、更新数量、计算总价、结账等。

**2. 用户体验**

- **目的**：确保软件的用户界面和交互设计能够符合用户习惯，提供良好的用户体验。
- **例子**：测试用户界面的可用性，比如按钮的响应、页面的布局等。

**3. 性能测试**

- **目的**：验证软件在高负载或真实使用条件下的性能。
  1. 模拟真实用户访问情况，评估系统在高并发场景下的性能表现。
  2. 发现系统在压力下的性能瓶颈，为系统调优提供依据。
  3. 评估系统能否满足性能指标要求，如响应时间、吞吐量等。
  4. 验证不同类型用户访问情况下的系统性能。
  5. 为系统容量规划提供数据支持。
  6. 确保接口在预期负载下能够正常运行，提供良好的用户体验。
- **例子**：模拟高用户访问量测试网站的响应时间和系统稳定性。

**4. 安全性测试**

- **目的**：确保软件的安全性，防止数据泄露和未授权访问。
- **例子**：测试数据加密、用户认证和授权等功能。

**5. 符合性和法规要求**

- **目的**：确保软件符合相关的行业标准和法律法规。
- **例子**：在医疗或金融软件中测试数据处理是否符合HIPAA或GDPR等法规要求。

**6. 数据的准确性和完整性**

- **目的**：确保软件处理和存储的数据的准确性和完整性。
- **例子**：测试数据库操作是否正确，数据是否在传输过程中保持完整。

**7. 可靠性和容错**

- **目的**：确保软件在出错或异常情况下能够可靠运行。
- **例子**：测试系统在网络中断或硬件故障时的表现。

业务测试是确保软件产品不仅在技术上符合规范，同时也在商业和实际应用层面满足用户需求的重要环节。通过业务测试，可以确保软件解决方案在实际运营中能够有效地支持业务目标和流程。

###  Alpha 测试

1. **定义**：Alpha 测试通常是软件开发团队内部进行的第一轮用户界面测试。在这个阶段，开发者通常会自己进行测试或请公司内部的其他专门的测试人员进行。

2. **环境**：Alpha 测试通常在开发环境中进行，而不是在用户环境中。

3. **参与者**：主要是内部开发者和测试人员。

4. **目的**：
   
   - 确保所有显而易见的缺陷已经被解决
   - 验证软件的功能和性能
   - 确保软件满足用户需求和规格说明
   
5. **局限性**：因为测试是在开发环境下进行的，所以可能无法完全模拟用户实际操作的环境和条件。

6. **时机**：通常在软件开发周期的后期，但在产品推向市场之前。

7. **反馈渠道**：通常通过内部渠道（如开发者或内部测试人员）。

   

### Beta 测试

1. **定义**：Beta 测试是第二轮的用户测试，通常由最终用户进行。
2. **环境**：Beta 测试通常在用户的实际环境下进行。
3. **参与者**：选定的终端用户、客户或者公开招募的测试人员。
4. **目的**：
   - 发现那些在 Alpha 测试中可能遗漏的缺陷
   - 收集用户关于界面可用性、功能和整体体验的反馈
   - 在实际应用环境下评估产品性能
5. **局限性**：由于测试通常是由用户进行的，所以可能不如 Alpha 测试系统。
6. **时机**：通常在 Alpha 测试后，但在最终版本发布之前。
7. **反馈渠道**：通常通过在线问卷、电子邮件或其他形式收集用户反馈。



两者的主要区别在于测试的执行者和测试环境。Alpha 测试主要是内部人员进行，目的更侧重于查找明显的缺陷和问题；而 Beta 测试则由实际用户进行，在真实环境下检验软件的可用性和稳定性。这两个测试阶段通常都是在软件发布之前进行的，以确保产品尽可能地无缺陷。



### 覆盖面（Coverage）

测试用例的**覆盖面（Coverage）**通常可以应用于白盒测试和黑盒测试，但在不同的测试环境下有不同的含义和应用方式。



**在白盒测试中：**

测试覆盖面常用于衡量源代码中有多少部分被测试用例覆盖了。这是一种更为技术、更侧重于内部结构的方法，通常涉及到以下几种类型的覆盖：

1. **语句覆盖（Statement Coverage）**: 测试用例覆盖了多少个代码语句。
2. **分支覆盖（Branch Coverage）**: 测试用例覆盖了多少个代码分支。
3. **路径覆盖（Path Coverage）**: 测试用例覆盖了多少条独立路径。
4. **函数或方法覆盖（Function/Method Coverage）**: 测试用例覆盖了多少个函数或方法。
5. **条件覆盖（Condition Coverage）**: 测试用例覆盖了多少个逻辑条件。

在白盒测试中，测试覆盖率通常用百分比来表示，例如，“语句覆盖率为80%”。



**在黑盒测试中：**

在黑盒测试中，覆盖面通常侧重于功能和需求，而不是代码。这里的覆盖面可能指：

1. **功能覆盖（Feature Coverage）**: 所有功能是否都有相应的测试用例。

2. **需求覆盖（Requirements Coverage）**: 是否所有的业务需求都被测试用例覆盖。

3. **数据覆盖（Data Coverage）**: 是否所有可能的输入数据都被考虑和测试。

4. **边界覆盖（Boundary Coverage）**: 是否测试了所有的边界条件。

5. **状态覆盖（State Coverage）**: 在某些特定类型的应用（如状态机）中，是否所有可能的状态都被测试。

   



### 安全测试

安全测试是软件测试的一个重要分支，旨在确认软件系统的数据和资源在各种威胁下的保护程度。其主要目的是识别和修复软件中的安全漏洞，防止未授权访问，保护数据的完整性、可用性和保密性。安全测试通常包括以下几个关键内容：

1. **漏洞扫描**

- 自动或手动检查系统中存在的已知漏洞，如缓冲区溢出、SQL注入、跨站脚本（XSS）等。

2. **渗透测试**

- 模拟黑客攻击来识别系统的安全弱点。这种测试尝试破坏系统的安全措施，以了解攻击者可能利用的漏洞。

3. **身份验证和授权测试**

- 确保系统能够正确验证用户身份，并且只允许授权用户访问特定的资源和数据。

4. **代码审查**

- 对软件源代码进行检查，以发现可能导致安全漏洞的编码错误或不安全的编程实践。

5. **安全配置测试**

- 检查软件及其所在环境的配置，以确保没有配置错误导致的安全漏洞。

6. **风险评估和威胁建模**

- 分析潜在的威胁和风险，并建立威胁模型，以帮助了解可能受到的攻击类型和影响。

7. **会话管理测试**

- 测试会话管理机制，包括会话超时、Cookie管理等，以确保会话数据的安全。

8. **加密措施测试**

- 检查数据加密、传输加密和存储加密的实现，确保敏感数据的安全。

9. **业务逻辑错误测试**

- 识别可能导致安全漏洞的业务逻辑错误。

10. **合规性测试**

- 确保软件符合相关的法律、标准和政策，如GDPR、HIPAA等。



## 质量保证（QA）

**1. 制定QA流程**

- **需求分析**：与项目经理、产品经理和开发团队合作，明确项目需求和质量标准。

  - ```
    “我与项目经理和开发团队紧密合作，详细分析项目需求，确定关键质量标准和验收标准，确保所有质量要求在开发初期就被明确和理解。”
    ```

  **质量计划**：制定详细的质量计划，包括质量目标、QA策略、测试计划和资源分配。

  - ```
    “我制定了详细的质量计划，明确质量目标、QA策略和测试计划，并合理分配资源，以确保项目质量管理工作的有序进行。”
    ```

  **过程定义**：定义开发和测试过程中的各个阶段及其质量要求，确保每个阶段都有明确的质量标准和检查点。

  - ```
    “我定义了开发和测试过程中的各个阶段及其质量要求，例如在设计阶段进行设计评审、在开发阶段进行代码审查和单元测试等，以确保每个阶段的质量控制。”
    ```



**2. 执行QA流程**

- **设计评审**：在设计阶段组织评审会议，评估设计文档是否符合需求和质量标准。

  - ```
    “在设计阶段，我组织了设计评审会议，邀请相关干系人共同评估设计文档，确保设计符合需求和质量标准，并在评审过程中发现和解决潜在问题。”
    ```

- **代码审查**：实施代码审查，确保代码质量和可维护性。

  - ```
    “我组织了定期的代码审查会议，通过同行评审的方式检查代码质量，确保代码的可读性、可维护性和符合编码规范。”
    ```

- **持续集成**：引入持续集成（CI）工具，确保代码变更能够及时集成并自动化测试，尽早发现和解决问题。

  - ```
    “我引入了Jenkins等持续集成工具，配置自动化构建和测试流程，确保每次代码提交后都能及时进行集成和测试，快速发现和解决问题。”
    ```

- **培训和指导**：为团队成员提供QA相关培训，提高全员质量意识和技能。

  - ```
    “我定期为团队成员提供质量管理和测试相关的培训，提高全员的质量意识和技能，确保大家都能正确理解和执行QA流程。”
    ```

  

### 质量控制（QC）

**1. 制定QC活动**

- **测试计划**：根据需求和质量标准制定详细的测试计划，明确测试范围、测试策略、测试用例和测试环境。

  ```
  “我根据需求和质量标准制定了详细的测试计划，明确测试范围、测试策略、测试用例和测试环境，确保测试工作的全面和系统性。”
  ```

- 测试用例设计：设计详细的测试用例，覆盖所有功能和非功能需求。

  ```
  “我设计了详细的测试用例，确保覆盖所有功能需求和非功能需求，例如性能测试、安全测试等，确保测试的全面性和有效性。”
  ```

**2. 执行QC活动**

- 功能测试：执行功能测试，验证系统是否按照需求正常工作。

  ```
  “我组织和执行了功能测试，验证系统是否按照需求正常工作，确保每个功能模块的正确性和稳定性。”
  ```

- 性能测试：执行性能测试，评估系统在高负载下的性能表现。

  ```
  “我使用JMeter等工具进行了性能测试，模拟高并发用户访问，评估系统在高负载下的性能表现，确保系统能够在预期负载下稳定运行。”
  ```

- 安全测试：执行安全测试，识别和解决系统中的安全漏洞。

  ```
  “我使用OWASP ZAP等工具进行了安全测试，识别和解决系统中的安全漏洞，确保系统的安全性和可靠性。”
  ```

- 缺陷管理：记录和跟踪发现的缺陷，确保缺陷得到及时修复和验证。

  ```
  “我使用JIRA等缺陷管理工具记录和跟踪发现的缺陷，确保缺陷得到及时修复和验证，并通过回归测试验证修复效果。”
  ```

**3. 质量改进**

- 缺陷分析：分析缺陷数据，识别根本原因，提出改进措施。

  ```
  “我定期分析缺陷数据，识别缺陷的根本原因，并提出改进措施。例如，通过分析某次发布中的缺陷，我们发现问题主要集中在某个模块，从而对该模块的开发和测试流程进行了优化。”
  ```

- 持续改进：通过PDCA循环（计划-执行-检查-行动）持续改进质量管理过程。

  ```
  “我采用PDCA循环（计划-执行-检查-行动）方法，持续改进质量管理过程，不断提高项目质量。例如，通过定期回顾和优化测试流程，提高了测试效率和质量。”
  ```



## 测试提效

**1. 自动化测试**

- **自动化回归测试**：
  
  - 目的：确保新的代码更改没有破坏现有功能。
  - 实践：使用工具（如 Selenium, TestNG, JUnit）自动运行关键功能的测试套件。
- **UI自动化**：
  
  - 目的：验证用户界面是否按预期工作。
  - 实践：模拟用户操作，如点击、输入、导航等，检查界面元素和反馈。
- **集成测试自动化**：
  
  - 目的：确保不同模块或服务间正确交互。
  - 实践：测试API接口、数据库交互、外部服务集成等。
- **性能测试自动化**：
  
  - 目的：确保系统在不同负载和压力条件下的性能表现。
  
  - 实践：使用工具（如 **JMeter, LoadRunner**）模拟多用户访问，测试响应时间、吞吐量等指标。
  
    

**2. 持续集成和持续部署（CI/CD）**

- **自动化构建和测试**：
  
  - 目的：快速发现和修复问题，减少集成问题。
  - 实践：在代码提交后自动运行构建和测试，使用 Jenkins, GitLab CI 等工具。
- **持续反馈**：
  
  - 目的：及时提供构建和测试结果的反馈。
  
  - 实践：通过邮件、聊天工具或仪表板提供反馈。
  
    

**3. 测试数据和环境管理**

- **有效的数据管理**：
  
  - 目的：确保测试数据的有效性和代表性。
  - 实践：使用真实数据的副本或合成数据，保持数据更新。
- **环境稳定性**：
  
  - 目的：提供可靠和一致的测试环境。
  - 实践：使用容器化（如 Docker）、虚拟化技术来快速配置和复制环境。
- **数据模拟和虚拟化**：
  
  - 目的：在缺少真实环境时进行有效测试。
  
  - 实践：使用API模拟工具（如 WireMock）来模拟外部服务。
  
    

**4. 代码质量和代码审查**

- **静态代码分析**：
  
  - 目的：提前识别潜在的代码质量问题。
  - 实践：使用 SonarQube 等工具自动分析代码质量。
- **代码审查**：
  
  - 目的：提高代码质量和团队协作。
  
  - 实践：同行审查，使用工具如 Gerrit 或 GitHub Pull Requests。
  
    

**5. 敏捷测试方法**

- **测试驱动开发（TDD）**：
  
  - 目的：确保代码质量和满足需求。
  - 实践：先写测试用例，再编写符合测试的代码。
- **行为驱动开发（BDD）**：
  
  - 目的：从业务需求出发，提高测试的有效性。
  
  - 实践：使用语言易懂的描述来编写测试，工具如 Cucumber。
  
    

**6. 高效的缺陷管理**

- **缺陷跟踪和管理**：
  
  - 目的：高效地记录、追踪和处理缺陷。
  
  - 实践：使用 JIRA 或 Bugzilla 等工具进行缺陷管理。
  
    

## 测试模型

###  v模型

以“编码”为黄金分割线，将整个过程分为开发和测试，并且开发和测试之间是

串行的关系

<img src="https://img-blog.csdn.net/20180818095813496?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTI5NDYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="软件测试的V模型" style="zoom: 67%;" />

**单元测试**：是模块测试，验证软件的基本组成单位的正确性，是白盒测试
**集成测试**：是模块间的测试，测试接口（软件各模块之间的接口和软件与硬件之间的接口）是否正确，是灰盒测试（白盒和黑盒结合）
**系统测试**：系统测试包括：冒烟测试 系统测试 回归测试
（1）冒烟测试：主干流程测试，确认软件的基本功能正常，可以进行后续的测试工作
（2）系统测试：是检测系统的功能、质量、性能能否满足系统的要求，包括功能、性能、界面、可靠性、兼容性等等，是黑盒测试
（3）回归测试：修改了旧代码之后重新进行测试，确认修改后的代码没有引入新的错误或导致其他代码产生新的错误
**验收测试**：是确保软件的实现能否满足用户的需求或合同的要求

**局限性：**V模型是基于瀑布模型的，V模型有一个缺点，就是将测试放在整个开发的最后阶段，没有让测试今早介入开发，没有在需求阶段就进入测试。



### W模型

W模型是由两个V模型组成，**一个是开发阶段，一个测试阶段**
可以看出，在W模型中开发和测试是**并行的关系**

![软件测试的W模型](https://img-blog.csdn.net/20180818095844322?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTI5NDYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**优点：**测试与开发并行，让测试今早介入开发环节，使测试今早发现问题今早解决。
**局限性：**虽然开发与测试并行了，但是在整个开发阶段，仍然是串行的，上一阶段未完全完成无法进入下一阶段，不支持敏捷模式的开发。



### H 模型

H 模型将测试活动分离出来，形成一个完全独立的流程，将测试准备活动和测试执行活动清晰地体现出来

<img src="https://pic1.zhimg.com/v2-4ce4a636177ec9cfc63fc37631205198_r.jpg" alt="img" style="zoom: 67%;" />

H 模型提倡者认为测试是一个独立的过程中，所以在H 模型中并没有看到关于开发的过程，而是测试的一个流程，当然这个测试的流程并不像V 模型和W 模型那样有明确的测试区分。H 模型演示了在整个生命周期中某个层次上一次软件测试的“微循环”。当测试条件准备完成，进入测试就绪状态后，所在测试H 模型中有一个测试就绪点，也就是测试有一个准入条件。通常情况下判断测试是否达到准入条件，应该检查以下几部分内容是否已经完成：

 该开发流程对应的测试策略是否完成;

 测试方案是否完成;

 测试用例是否完成;

 测试环境是否搭建好;

 相关输入件、输出件是否明确。

也就是说，通常我们要检查上面一些内容是否完成，再确定我们是否需要进入下一个阶段的测试。当测试条件成熟，并且测试准备工作已经完成，进入了测试就绪点，测试执行活动才可以进行。

H 模型中还有一个“其他流程”的测试，这个观点强调了测试其他不一定要是常见的应用程序也可以其他的内容，这可以理解为整个产品包中所有的对象，包括开发阶段的一些设计流程，这样将测试的范围直接扩展到整个产品包，而非W 模型中提到的代码、需求或其他相关说明书。

与V 模型和W 模型不同的是，H 模型的核心是将软件测试过程独立出来，并贯穿产品的整个生命周期，与开发流程并行进行，不需要等到程序全部开发完成才开始执行测试，这充分体现了软件测试要尽早准备、尽早执行的原则。不同的测试活动可以按照某个次序先后进行，当一次测试工作后产品质量无法达到要求时，可以反复进行多次测试。

**总之H 模型具有以下特征：**

(1)测试是一个独立的过程;

(2)测试达到准入条件，才可以执行;

(3)测试对象是整个产品包，而不仅仅是程度、需求或相关说明书;





## 常用自动化测试工具

https://zhuanlan.zhihu.com/p/603190738

https://blog.csdn.net/weixin_44015669/article/details/121082810

### **Selenium**--WebUI自动化测试

Selenium 是一个广泛用于自动化网页操作的工具库。以下是一些 **Selenium** 常见的基础操作：



- **初始化 WebDriver**

在进行任何操作之前，需要初始化一个 WebDriver 对象。

```python
from selenium import webdriver

# 初始化一个 Chrome WebDriver 实例
driver = webdriver.Chrome()
```



- **打开网页**

使用 `get` 方法打开一个网页。

```python
driver.get("https://www.example.com")
```



- **元素定位**

Selenium 提供了多种方法来定位页面元素，如 `find_element_by_id`, `find_element_by_name`, `find_element_by_css_selector`, 等。

```python
# 通过 ID 定位
element = driver.find_element_by_id("element_id")

# 通过 Name 定位
element = driver.find_element_by_name("element_name")

# 通过 CSS 选择器定位
element = driver.find_element_by_css_selector("tag#id .class")
```



- **元素操作**

  找到元素后，你可以进行各种操作。

  **输入文本**

```
element.send_keys("some text")
```

**点击操作**

```
element.click()
```

**清除输入框内容**

```
element.clear()
```

- **等待**

为了确保页面元素正确加载，通常会使用等待。

**显式等待**

```
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, "element_id")))
```

**隐式等待**

```
driver.implicitly_wait(10)
```



- **执行 JavaScript 代码**

有时候，某些操作可能需要直接执行 JavaScript 代码。

```
driver.execute_script("arguments[0].click();", element)
```



- **关闭浏览器**

完成测试后，记得关闭浏览器。

```
# 关闭当前窗口
driver.close()

# 退出浏览器并结束 WebDriver 会话
driver.quit()
```



### Appium -- AppUI自动化测试

Appium是一个开源工具，用于自动化移动应用程序的测试，无论是原生应用程序、混合应用程序还是移动Web应用程序。它支持iOS、Android和Windows平台。

- #### 主要特点

1. **跨平台**：Appium允许用户使用相同的API为iOS和Android编写测试脚本，这大大提高了代码的复用率。
2. **语言无关性**：Appium本身是用Node.js编写的，但它支持许多编程语言，包括Java、Python、Ruby、JavaScript、C#和PHP，这是因为它是一个WebDriver服务器，理论上它能够支持任何使用WebDriver客户端库的语言。
3. **原生API访问**：测试脚本可以使用设备和平台的原生API执行操作。
4. **无需重新编译**：使用Appium时，不需要对应用程序进行任何修改或重新编译，这使得测试过程更加方便快捷。
5. **WebDriver兼容**：Appium实现了WebDriver协议，因此它被设计为满足移动自动化的WebDriver标准。

- #### 工作原理

Appium工作原理基于客户端-服务器模型：

- **服务器**：Appium运行作为一个服务器，它接受来自客户端的连接和指令。
- **客户端**：开发者编写测试脚本使用Appium的客户端库，这些库向服务器发送HTTP请求。

服务器接收这些请求并使用移动平台的自动化框架来执行这些请求指定的动作。例如，对于iOS，它可能使用XCUITest；对于Android，它可能使用UIAutomator或Espresso。

- #### **例子**

下面是一个使用 Python 编写的基本 Appium 测试脚本的例子，它将启动一个 Android 应用，执行一些简单的动作，然后关闭会话。

```python
from appium import webdriver
import time

# 设置启动的设备和应用信息
desired_caps = {
    'platformName': 'Android',  # 平台名称
    'platformVersion': '9',     # 系统版本号
    'deviceName': 'emulator-5554',  # 设备名称，通过 `adb devices` 获取
    'appPackage': 'com.example.androidapp',  # 应用包名
    'appActivity': '.MainActivity',  # 应用的主Activity名称
    'automationName': 'UiAutomator2',  # 自动化引擎
    'noReset': True  # 不清除应用数据
}

# 初始化驱动，设置 Appium 服务地址
driver = webdriver.Remote('http://localhost:4723/wd/hub', desired_caps)

# 给应用启动和加载留出时间
time.sleep(5)

# 查找元素并进行操作，这里以点击操作为例
# 需要替换为你要交互的元素的定位方法
element = driver.find_element_by_accessibility_id('SomeAccessibilityID')
element.click()

# 等待一些时间以便观察
time.sleep(2)

# 退出会话
driver.quit()
```

在这个脚本中，首先需要确保已经安装了 Appium 的 Python 客户端库。如果没有安装，可以通过以下命令安装：

```bash
pip install Appium-Python-Client
```

脚本的关键点如下：

- `desired_caps` 是一个字典，用于配置启动应用的一些选项，如平台版本、设备名称和待测应用的信息。
- `webdriver.Remote` 方法用于创建一个会话。这里需要指定 Appium 服务的 URL 和 `desired_caps`。
- `find_element_by_accessibility_id` 是查找元素的方法之一，Appium 支持多种定位策略，如 ID、XPath、Android UIAutomator 等。你应该根据自己的应用情况来选择最适合的定位方法。
- 最后，使用 `driver.quit()` 来关闭会话。



### **Postman**--接口测试

Postman 提供功能强大的 Web API 和 HTTP 请求的调试，它能够发送任何类型的HTTP 请求 (GET, POST, PUT, DELETE…)，并且能附带任何数量的参数和 Headers。



### **Jmeter**--性能测试

最初是为了测试Web应用程序而开发的

1. **模拟高负载**：JMeter 可以模拟多个用户同时访问一个服务，以测试该服务在高负载下的性能和稳定性。
2. **性能分析**：JMeter 不仅可以测试服务在极限负载下的性能，还可以分析服务在不同负载级别下的整体性能。

> ### 创建测试计划
>
> 打开 JMeter，创建一个新的测试计划。测试计划是你的压力测试的蓝图，它定义了要执行的测试和预期的负载。
>
> ### 配置线程组
>
> - 在测试计划中添加一个线程组，这代表了一组用户。
> - 设置线程数（用户数）、施加负载的时间以及循环次数。
>
> ### 添加采样器
>
> - 在线程组下添加HTTP请求采样器。这是你模拟发送到游戏服务器的实际请求。
> - 配置服务器名称或IP、端口号以及任何相关的HTTP路径和参数。
>
> ### 添加监听器
>
> - 为了查看测试结果，需要在测试计划中添加监听器。常用的监听器有图形结果、表格结果和树视图结果等。
> - 监听器可以帮助你分析响应时间、错误率等关键指标。
>
> ### 配置测试数据
>
> - 如果需要，你可以通过CSV Data Set Config 等方式添加测试数据，以模拟不同用户的不同输入。
>
> ### 运行测试
>
> - 运行测试计划，JMeter 将模拟多个用户对服务器进行压力测试。
> - 观察监听器中的结果，以了解服务器在高负载下的表现。
>
> ### 分析结果
>
> - 分析结果，查找性能瓶颈、响应时间延迟等问题。
> - 根据测试结果调整服务器配置或优化游戏后端代码。
>
> ### 迭代测试
>
> - 对所做的更改进行迭代测试，以确认性能提升的效果。
>
> ### 注意事项
>
> - 确保在授权的环境下进行测试。对于没有授权的服务器进行压力测试可能违反法律规定。
> - JMeter 主要用于测试基于HTTP/HTTPS的服务。对于非HTTP/HTTPS的游戏服务器，可能需要使用其他工具或方法。
>
> 由于JMeter主要用于Web应用，对于移动游戏的直接压力测试可能需要专门的工具或定制脚本。如果游戏后端使用的是标准的Web技术或RESTful API，那么JMeter 是一个非常有用的工具。如果游戏使用其他协议（如WebSocket、TCP/IP），你可能需要寻找或开发更适合这些协议的压力测试工具。



### **Jenkins**--CI/CD

**Jenkins** 是一个开源的自动化服务器，主要用于持续集成和持续部署（CI/CD）的自动化。它支持开发者在软件开发过程中自动化各种任务，如构建、测试和部署应用程序。

**主要特点：**

1. **开源**：Jenkins 是一个自由和开源的软件，拥有一个活跃的社区。

2. **插件丰富**：具有广泛的插件生态系统，可以扩展其功能以适应几乎任何CI/CD的需求。

3. **易于安装和配置**：提供易于使用的界面和配置选项。

4. **跨平台**：支持多种操作系统。

5. **支持多种语言和工具**：可以与各种编程语言和构建工具（如Maven、Gradle）集成。

6. **可扩展**：可以通过编写自己的插件来扩展功能。

   

**基本使用方法：**

1. **安装**：
   - Jenkins 可以在多种平台上运行，包括Windows、Linux和macOS。可以从 Jenkins 网站下载并安装。
   - 安装后，通常通过浏览器访问 Jenkins 的Web界面进行配置。

2. **配置**：
   - **配置Jenkins**：设置基本参数，如端口、JVM选项等。
   - **安装插件**：根据需要安装插件，以增强 Jenkins 的功能。
   - **设置用户和权限**：创建用户账户并分配适当的权限。

3. **创建项目（Job）**：
   - 在Jenkins中，每个任务或工作流程都被称为一个“项目”。
   - 设置源代码管理（如Git），定义代码的获取方式。
   - 定义构建触发器，例如在每次代码提交时自动触发。

4. **构建脚本**：
   - 编写构建脚本，定义如何构建项目。可以使用各种构建工具和脚本语言。

5. **测试和构建**：
   - 配置自动化测试，确保代码质量。
   - 执行构建过程，生成可交付的软件。

6. **部署**：
   - 在构建后，可以配置 Jenkins 自动将软件部署到服务器或其他环境。

7. **监控和报告**：
   - 监控构建过程，并在构建失败时收到通知。
   - 查看和分析构建报告，如测试结果和代码覆盖率。

**高级用法：**

- **Pipeline**：Jenkins Pipeline 提供了一种扩展的方式来定义CI/CD流程，使用一个文本文件（Jenkinsfile）来定义构建、测试和部署的流程。

- **分布式构建**：可以配置 Jenkins 以在多台机器上分布式运行构建任务。

  

### **Junit--单元测试**

  Junit单元测试框架—基于java语言对的主流单元测试框架 

  @**beforeClass**—位于数据准备前期或者其他前期准备（测试类调用前） 

  --用于提取代码中的共用部分减少冗余，只能声明注解一次 

  --必须在public static void,方法名随意，只运行一次。 

  @**AfterClass**—位于所有用例运行之后，处理测试后续工作。 

​        --测试类被调用运行结束之前，只能声明注解一次。 

​        --必须在public static void,方法名随意，，只运行一次。 

  @**Test**—在Junit3中通过对测试类和测试方法的命名来确定是否为测试 

​     --在Junit4中，只要在方法前加@Test就行，此注解必为单元测试。 

​     --在一个测试类可多次注解，每个只被执行一次，必须是public void 

​     --可以抛异常 



  **使用Assert断言** 

  1、断言相等：**assertEquals**(100,x)，判断对象是否为同一个 

  断言不相等：**assertNotEquals**(100,x)，判断对象是否不为同一个 

  2、断言数组内容相等：assertArrayEquals({1,2,3},x) 

  3、断言浮点数相等：assertEquals(3.1416, x, 0.0001)（必须设置误差值） 

  4、断言为null：assertNull(x) 

  5、断言真伪性：assertTrue(x > 0)/assertFalse(x < 0) 

  6、 校准测试函数，使用操作符'=='比较实际和预期的是否重复



### Unittest

`unittest` 是 Python 内置的一个测试框架，它是基于 Java 的 JUnit 框架开发的，支持自动化测试、共享测试代码、聚合测试结果等功能。`unittest` 提供了丰富的工具来构建和运行测试，使得编写测试用例变得更加简单。

### 主要特点

1. **测试组织**：`unittest` 允许您使用类来组织测试代码。通常，每个测试类对应一个被测试的模块，每个测试方法对应模块中的一个函数或功能。

2. **断言方法**：提供了一系列的断言方法来检查代码行为是否符合预期，如 `assertEqual()`, `assertTrue()`, `assertFalse()` 等。

3. **测试套件**：可以创建测试套件（Test Suite）来聚集不同的测试用例和测试集。

4. **测试运行器**：通过命令行或程序的方式运行测试，并提供了多种输出格式。

5. **测试装置**：支持设置 `setUp()` 和 `tearDown()` 方法，用于在每个测试前后进行初始化或清理工作。

### 基本使用

下面是一个使用 `unittest` 的基本示例：

```python
import unittest

class MyTest(unittest.TestCase):
    def setUp(self):
        # 初始化工作
        pass

    def test_feature_one(self):
        # 测试功能一
        self.assertEqual(1 + 1, 2)

    def test_feature_two(self):
        # 测试功能二
        self.assertTrue(1 + 1 == 2)

    def tearDown(self):
        # 清理工作
        pass

if __name__ == '__main__':
    unittest.main()
```

在这个示例中：

- `MyTest` 类继承自 `unittest.TestCase`，代表了一组测试。

- `test_feature_one` 和 `test_feature_two` 是具体的测试方法。测试方法的命名通常以 `test` 开头，这样 `unittest` 测试运行器才会自动识别和执行它们。

- `setUp` 和 `tearDown` 分别用于测试前的准备和测试后的清理工作。

- 最后的 `unittest.main()` 提供了一个命令行界面，用于运行脚本中的测试用例。

  

## 测试面试常见问题

### 自己对于测试岗位的优势

1. **专业技能：** 强调你拥有的与测试相关的专业技能，比如编写测试用例、自动化测试、性能测试等，以及你熟悉的测试工具和框架（如**Selenium、JMeter、Postman**等）。
2. **问题解决能力：** 测试工作经常需要解决各种**复杂的技术问题**。描述你解决问题的能力和过往经验，特别是那些能够展示你如何有效发现并解决问题的情况。
3. **细心和耐心：** 测试需要**细致的检查和反复的验证**。展示你具备高度的细心和耐心，以及你在以往工作中如何体现这些品质的例子。
4. **学习能力：** 测试工程师需要持续学习新工具和技术。提供实例说明你是如何**快速学习新工具**并将其应用于实际工作中的。
5. **沟通能力：** 强调你的**沟通技能**，说明你如何有效地与开发团队协作，以及你是如何确保问题被理解和解决的。
6. **业务理解：** 如果你对应用的业务领域有深入理解，这将是一个巨大的优势。说明你对业务流程的理解**如何帮助你更好地设计测试用例和发现潜在问题**。
7. **质量导向：** 强调你对高质量标准的承诺，以及你在保证产品质量方面的经验和成功案例。
8. **适应能力：** 展示你适应新环境和变化的能力，这对于测试岗位来说非常重要。



"我对于软件测试岗位的热情源自于我对技术的深刻理解和不断完善产品的渴望。作为一个具有扎实的编程基础和自动化测试经验的测试工程师，我熟悉多种测试框架，如Selenium和JMeter，并且我能够迅速适应新工具和技术。我擅长跨部门沟通，能够有效地与开发团队协作，确保测试计划的顺利执行，并提供深入的问题分析。此外，我的业务理解和对质量的执着追求使我能够在测试流程中发挥关键作用，确保产品在上市前满足最高的质量标准。我认为，我的专业技能结合持续学习的态度和对质量的关注使我成为这个职位的理想候选人。"



### 对测试开发的理解以及他们日常会做什么工作

测试开发（Test Development 或 Test Automation Development）是软件测试的一个子领域，专注于通过编程来自动化测试过程。测试开发不仅涉及编写自动化测试脚本，还包括设计和维护自动化测试框架、与开发团队紧密合作以提高软件质量，以及参与**持续集成（CI）和持续交付（CD）流程**。下面详细地介绍一下测试开发的一些核心职责和他们日常可能会做的工作。

**核心职责**

1. **自动化测试脚本编写**：使用编程语言（如 Python、Java 等）和自动化测试工具（如 **Selenium**、**Appium**、**Junit** 等）来编写测试脚本。
2. **测试框架设计与维护**：设计和建立自动化测试框架，以便更容易、更快捷地编写和运行测试脚本。
3. **测试用例设计**：与需求分析师、产品经理和开发人员合作，理解新功能或改动，然后设计相应的测试用例。
4. **持续集成与持续交付（CI/CD）**：将自动化测试脚本融入CI/CD管道，确保每次代码更改都能自动触发相关测试。
5. **代码审查与质量保证**：参与代码审查，以确保测试代码质量；同时也关注产品代码，帮助开发人员提高代码质量。
6. **性能测试**：使用工具如 JMeter 进行性能、压力和负载测试。
7. **文档编写与维护**：编写测试报告和文档，以记录测试计划、测试用例和测试结果。

**日常工作流程**

1. **需求分析**：在一个迭代或开发周期开始时，与团队成员一起了解即将开发或修改的功能。
2. **测试计划与用例设计**：根据需求分析结果，制定测试计划并设计测试用例。
3. **环境准备**：设置和维护测试环境，包括数据准备、服务器配置等。
4. **编写与调试测试代码**：按照测试用例编写自动化测试脚本，并进行调试。
5. **执行测试**：运行测试脚本，手动或自动地执行测试用例。
6. **结果分析与报告**：分析测试结果，找出问题并编写测试报告。
7. **缺陷跟踪与修复**：与开发人员一起跟踪和修复在测试中发现的缺陷。
8. **代码提交与CI/CD**：将测试代码提交到版本控制系统，并确保它被纳入CI/CD流程。
9. **回归测试与维护**：在软件发布后，进行回归测试以确保新添加或修改的代码没有引入新的问题。



### 为什么选择测试开发

1. 技术层面

**全面的技术观点:** 测试开发不仅涉及到测试，还需**理解软件的开发过程**，这为**深入了解整个系统**提供了机会。

**自动化与编程**: 现代测试开发大量依赖自动化，这也意味着有很多编程工作，对于喜欢编程的人来说是个好选择。

2. 问题解决

侦查与调查: **良好的测试能够发现隐藏的问题**，这需要扎实的问题解决能力。

质量保证: 你的工作直接**影响产品质量**，这是个相当有成就感的工作。

3. 学习与成长

- 不断学习: 软件工具和方法论不断更新，需要持续学习。

- 多元化的挑战: **测试开发会接触到多种类型的项目和问题**，这有助于个人成长

  

### 如何定位错误发生的位置

区分前端和后端的bug，主要是基于bug表现出的特点以及bug所在的软件架构层面。以下是判断bug是前端还是后端的一些常见方式：

- #### 前端Bug的特点：

- **界面问题**：布局错位、样式不一致、动画不流畅、响应式设计在不同设备上显示异常等。

- **客户端功能**：页面元素（如按钮、输入框）不响应用户操作，或者响应行为与预期不符。

- **浏览器兼容性**：功能在某些浏览器上正常，在其他浏览器上不正常。

- **JavaScript错误**：控制台（Console）报错，如`undefined is not a function`、`null is not an object`等。

- **性能问题**：页面加载缓慢，滚动条卡顿等，可能与JavaScript的效率、图片的大小或者过度的DOM操作有关。

- **响应数据处理**：获取到后端数据后，前端处理或渲染数据的方式有问题，导致显示不正确或功能异常。

  

- #### 后端Bug的特点：

- **服务器错误**：返回HTTP错误代码，如`500 Internal Server Error`、`404 Not Found`等。

- **性能瓶颈**：慢查询、内存泄露、CPU使用率高等，可能导致系统响应缓慢或服务不可用。

- **逻辑错误**：后端逻辑处理不当，返回的数据不符合预期，比如计算错误、数据排序或筛选错误。

- **数据库错误**：数据持久化问题，如无法插入、更新或删除数据库中的记录，或者数据一致性、完整性问题。

- **安全问题**：身份验证、权限检查、数据加密等安全措施出现问题。

- **接口问题**：API返回不正确的数据结构或内容，或者API本身不稳定导致前端调用失败。

  

- #### 如何区分：

1. **检查浏览器开发者工具**：开发者工具中的Network和Console选项卡是区分前后端bug的重要工具。如果在Console中出现JavaScript或资源加载错误，很可能是前端bug。如果Network中显示的HTTP响应状态码为4xx或5xx，可能是后端bug。

2. **复现问题步骤**：尝试复现bug时仔细观察，在哪一步出现问题，是否是发送请求给服务器后出现的问题。

3. **查看日志**：后端日志可以提供请求处理的详细信息。如果日志中有异常或错误信息，可以帮助定位是后端的bug。

4. **代码审查**：如果bug的表现不足以判断是前端还是后端的问题，那么需要通过审查相关的代码逻辑。

5. **调试和单元测试**：使用调试工具和编写单元测试可以帮助确定bug的位置。

6. **团队沟通**：与团队中的前端和后端开发人员沟通，可以快速定位问题。

   

### 如何和开发人员确认一个BUG

**1. 提供详尽的证据**

确保你提供了详细的bug报告，包括：

- **重现步骤**：提供清晰、可重现bug的步骤。
- **截图或视频**：如果可能，附上显示bug的截图或录屏视频。
- **日志文件**：包括任何相关的系统或应用**日志文件**。
- **测试环境描述**：详细说明bug出现时的环境设置，包括操作系统、浏览器版本、设备信息等。
- **预期与实际的结果**：说明期望的行为是什么，实际发生了什么。

**2. 讨论而非争论**

避免对抗态度，以一种合作的姿态接近问题：

- **理解开发视角**：试着了解为什么开发者不认为这是个bug。**可能是对功能的误解，或者是需求的不明确。**
- **询问开发者的意见**：他们可能有不同的看法或对特定行为有不同的理解。

**3. 明确需求和规范**

有时候，**一个行为是否算bug取决于需求和规范的定义**：

- 如果需求文档不明确或存在歧义，那么需要和团队一起澄清。
- 参照产品规范和设计文档，确定行为是否符合预期。

**4. 复制bug**

尝试在不同的环境中复制该bug，以证明这不是特定环境下的偶然问题。

**5. 请求第三方意见**

- 有时候，将问题提交给团队中的另一位开发人员或测试人员评估，可以提供新的视角。
- 需要时，可以召开简短的会议，让相关人员共同查看bug的表现。

**6. 利用项目管理工具**

- 在项目管理或缺陷跟踪系统中记录bug，这样可以正式跟踪问题。
- 评估该bug的优先级和严重性，这可能影响开发团队对待这个问题的态度。

**7. 与项目经理或团队负责人沟通**

- 如果问题依旧无法解决，可能需要升级到项目经理或团队负责人，让他们来评估和决定如何处理。



## 性能测试

### 1.普通性能场景设计

模式：基本上就是一个线程组下挂了很多请求

线程组

 1.线程数：模拟的并发用户数量

  jmeter本身是没有对线程数做限制的，但是jmeter启动这些并发用户数时，需要消耗资源，收电脑cpu的主频   限制，一台电脑不可能创建无限量的线程数。

 实际情况，**http协议**的脚本，线程数，大概能1500左右至2000个可能产生(理论)，但是可能会出错，so1000左右比较保守，肯定能产生。

 也就是说，1台电脑，**http协议**脚本，保守估计可以产生约1000个并发用户数。

 如果你想模拟超过1000并发用户数(针对HTTP 协议)，你可能需要考虑**分布式**

ramp-up时间

1.启动所有线程数启动的时间(前置条件:线程数在合理的范围。如1台1000内，你设置5000就不合理)

在ramp-up时间结束点，所有的人会产生。

在ramp-up时间内，是否均匀产生并发用户数，是不确定的(如5s，但是中间1s产生多少，第2s第5s产生多少并不知道是不是平均分配)。

在启动时间内，产生的并发用户数，一产生，就去发起请求。

启动了并发用户，就会去发起请求，不同时间产生的并发用户数，与前面产生的并发用户数，调用的接口可能不一样(有的下单，有的注册，有的登录)，jmeter做性能测试，更多时候，使用的是，广义并发。

ramp-up时间要大于等于1

**线程数 + ramp-up时间，怎么设置才比较合理?**

500以内的并发用户数，ramp-up 2-4s（经验之谈）

500-1000并发用户数 ，ramp-up  5s

\>1000     ramp-up      5- 8s秒

一个原则：ramp-up时间在总执行时间中，占比要很低

一般的情况，一个性能测试的总时间 几分钟 - 几十分钟

循环次数

 默认必须大于等于1

 循环次数，就是每个并发用户数要去执行的请求数量

 复习框 永远 一直循环，知道你点击停止，才会

  Q：这个停止会有问题吗

A：会有问题，会导致请求报错，或卡死

**永远**应该怎么用呢？

要与调度器一期使用

 **必须把两个勾都勾选 如图1**

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=YTVkYTAxZjcxODYyNjRhMDdiYmM2ODJkNzU0MjQ0ZjBfU2dTMTRvWWQ0ZlhRbDZzb29QWGRMSWdodlYwRUg4amJfVG9rZW46TTRUcGJkbmxtbzQyb1B4SDAzc2N1eGxCbmloXzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

​                             图1

**场景**

30个并发用户，持续运行300s

聚合报告(图1.2)：avgRT：51ms ； 90%： 77ms；  avgTPS：192.5   异常：25.79%

结论：

1. 响应时间满足 RT<150ms  如图1.3
2. 30个人，avgTPS：192.5              平均1个用户发送约6.4个请求
3. avg异常率非常高**25.79%**

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=Y2M2Zjc2YWEyZWQ2YmJlN2M0YTNjZjg0NjMzYTgyMTZfeTRuRU1SSUVhT3l5WFBuUDdINFg1ZVpBZ2ZIRWJrcG5fVG9rZW46TTJIRWI2cDFBb1R1SnF4bE5tQmNjZzlnblRkXzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

​                                                     如图1.2

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=MjBmNjg5N2YwODA2OTllOWIzMGFhMDQ5YTY0YzFiMDVfSHRmcmJXcW9PbmtKa1dLMTFLWkxMQnllUkdyYm9ieUNfVG9rZW46TWFjUmJGUGRRb09HcTF4eXViWWNvejBybmdiXzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

​                                                          如图1.3

### 2.阶梯性能测试场景(负载测试场景)                                   

**目标：得到最大并发用户数**

负载测试：逐步增加并发用户数 

在阶梯线程组，执行过程中，我们的并发用户数是时刻发生变化

在阶梯线程组，执行过程中，我们的并发用户数是时刻变化的

 缓起步，快启动

目的：找拐点区间

必须装**插件**(jmeter)：jpgc安装 如图2.1

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=NmRhZmZlMTU2MTZmNTJhMWRkYmViZmZiM2Q4NTk5YTlfRkx2dElPUHJtNEFXYVYwdVhlRGhwMWQ1OEdZNWc4NWtfVG9rZW46UEk1N2JHbFl5b1ZXSjZ4TVlaeGNMM244bjFkXzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

​                                                                 图2.1

方法一：

**插件参数设置：** jp@gc - Stepping Thread Group (默认：用5秒钟 增加10个并发用户数，持续运行30秒)

阶梯加压

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=Yjg3MDZkNzA3YzY0ZDQzMGM2YWIxMThlZjhkNzJiMmFfT0pITGlBSG5rMVUyRHBQZEZKcFN4d25xYloxa2xWTXRfVG9rZW46VjFieWJ1eUhQb1F0Wnl4OVZDdmN6OFJ5blhiXzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

This group will start：表示总共要启动的线程数；若设置为 100，表示总共会加载到 100 个线程

First，wait for：从运行之后多长时间开始启动线程；若设置为 0 秒，表示运行之后立即启动线程

Then start：初次启动多少个线程；若设置为 0 个，表示初次不启动线程

Next add：之后每次启动多少个线程；若设置为 10个，表示每个梯次启动 10 个线程

threads every：当前运行多长时间后再次启动线程，即每一次线程启动完成之后的持续时间；若设置为 30 秒，每梯次启动完线程之后再运行 30 秒

using ramp-up：启动线程的时间；若设置为 5 秒，表示每次启动线程都持续 5 秒（和基础线程组的ramp-up一样意思）

then hold load for：线程全部启动完之后持续运行多长时间，如图：设置为 60 秒，表示 100 个线程全部启动完之后再持续运行 60 秒

finally，stop/threads every：多长时间释放多少个线程；若设置为 5 个和 1 秒，表示持续负载结束之后每 1 秒钟释放 5 个线程

- 从第0秒开始启动线程，每 5 秒内启动10个线程并且运行30秒，以此循环，直到一共启动了 100 个线程
- 当已启动 100 个线程后，持续负载运行60秒
- 持续负载运行60秒后，每 1 秒释放五个线程，直到全部线程被释放

2.1当完全不知道项目的性能瓶颈范围时，我们怎么设置0-100， 0-200，0-300等

已经找到范围，怎么设置

案例：压测策略 20增压到40线程数

​        每次增加5个线程数后，持续60s

被测接口如下：

| baseinfo                 | C端查询桩群信息               | /mtsV2/c/stub/group/info | 是   |
| ------------------------ | ----------------------------- | ------------------------ | ---- |
| C端查询桩信息            | /mtsV2/c/stub/qryInfo         | 是                       |      |
| C端查询桩群信息info-only | /mtsV2/c/stub/group/info-only | 是                       |      |
|                          |                               |                          |      |

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=NTMwZjk2NDk0MjUxZDc4YWNhYzYzMTgyY2EwNTliYTNfNFZwRjc2Z25ENWN2cklFWDR1b09ERDgwT3lnUHBiZnRfVG9rZW46RWFON2JrMGhxb0kxUEp4QjIzNmNyU2FhbmljXzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

聚合报告:5分钟测试结果总请求数在18.6w

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=ZmNiZTQxZDg0YTRjOTdjOTg4OTYwYmZlY2Y1N2RkYmJfcXJKaVFrRU1EdXMxMU4xY014V0NSTnREQk5qV2FuOXFfVG9rZW46VzB5S2IxSVJ2b3FJeGt4VHd3RmNGN2pObklnXzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

​                                                             聚合报告

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=MmUzM2IzZjhmN2U1MTA4YjEzMDJlNzA0ZDQ0ZjE2ZmVfQTFyakxXcEJPd1FTanZTYjRNZ0lETW5aUHBLTEJiaXBfVG9rZW46Slllb2JRTU9vb1dnZnZ4QUhqY2NGTWdRbms2XzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

​                                              响应时间**(压约1分半后，响应时间开始相交，且响应时间不稳定且在增加)**

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=ODQ1OTJkMDIwNDg4MzlkODhkMjg1YWU1OGI2MDRkYzFfNThYUHpzckVYeXFIUEo5OFRmbGJINExEb3B4Mnl4QUlfVG9rZW46SVA1bmJzbERYb1l3c214aVFzYmNHOXBkbkpBXzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

​                              jp@gc - Response Times Over Time图 随时间变化的响应时间**(1分半后开始不稳定)**

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=YzY1MmUzYjI1ZTkwZDY1ZmU2NmIxMTk5ZGZkZGVjYmVfQkZmcURRSHZITExqcWV5Z1c4WmtnYmdaRDVETVVndHRfVG9rZW46SGFZMGJhUjNtb2tvVDJ4T2xyZ2M1UlFkbnhkXzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

​                                       jp@gc - Transactions per Second图（在约1分25s后，失败率开始直线上升）

结果：在压测试过程中，接口在1分半的时间点后，出现抖动不稳定，此时并发用户数(线程数)在**25个线程数**,在往上增加线程数，响应时间抖动率在增加，均值响应时间也会增加，错误率开始极具上升.

方法二：Concurrency (**官方建议用这个**)

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=MGIzNjc1YWU0MjhjOGIxNzZkMjE5NTVjZTAzODRiNDVfajA0Zk9HU1N0aVYxV01sejRkRGpSb3lvZXhiODd5WEVfVG9rZW46RTYyeWJGUnlEb3FXNFJ4V204QmN0TjlObldkXzE3MTYzMDg1Mzk6MTcxNjMxMjEzOV9WNA)

前置条件：

- **Time Unit**：时间单位（分钟或者秒），我这里设置的是：秒

Target Concurrency：目标并发（线程数）

Ramp Up Time：启动时间；若设置 1 min，则目标线程在1 min内全部启动

Ramp-Up Steps Count：阶梯次数；若设置 6 ，则目标线程在 1min 内分六次阶梯加压（启动线程）；每次启动的线程数 = 目标线程数 / 阶梯次数 = 60 / 6 = 10

Hold Target Rate Time：持续负载运行时间；若设置 2 ，则启动完所有线程后，持续负载运行 2 min，然后再结束

Time Unit：时间单位（分钟或者秒）

Thread Iterations Limit：线程迭代次数限制（循环次数）；默认为空，理解成永远，如果运行时间到达Ramp Up Time + Hold Target Rate Time，则停止运行线程【不建议设置该值】

Log Threads Status into File：将线程状态记录到文件中（将线程启动和线程停止事件保存为日志文件）；

这个脚本： 并发用户数500，在100秒内，分多少阶梯100个阶梯，达到之后运行多少勒

Hold Target Rate Time 这里设的30，为30秒



### 3.混合场景(重点：不同数量的人，向不同的接口发起请求)

混合场景：**不同数量的并发用户数，向不同的接口发起请求——**这种才**是真正的混合场景**，才真正符合企业产品的实际情况

"假"混合场景：在一个线程组中，添加逻辑控制器，控制我们脚本的运行，这种，是把脚本混合了，但是与生产环境的情况还是有差异。

每个线程组挂一种业务or接口**(多线程并发执行**) 如图5.1

三个红色箭头，代表三种不同业务 (如果不能理解再比喻：一个线程组放-注册，一个线程组放-登录，一个线程组放-查询首页)

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=MjBiMjYwNTI3NWFhODY1N2E0ZjViZGY3OTE4MmQxOGNfbjFXYzJVRkZSSkx1MHhmR3hGdlUwUlBjdUtWQk1rVmFfVG9rZW46R2hzeWI2ZzZsbzFIZm54QmxEcWM5cVR2bnNkXzE3MTYzMDg3Mzc6MTcxNjMxMjMzN19WNA)

​                                                                       如图5.1

#### 5.1 混合场景的脚本(案例1)：                                                       

结果：不稳定，错误率异常高



脚本信息如下：

线程组1   设置40人并发

线程组2   设置20人并发

线程组3   设置30人并发

总共：**90个用户并发的量（这种情况最接近大量用户的正常访问）**



**1C端查询桩群信息 40并发用户数**

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=ZDdmNjk1NGJhZjBhNmU0MzQyY2I5MTY4OGE0NmJhMGZfblhMd21VV0EwODZvUFhzRVh4V09DTksxcTR5akFERWJfVG9rZW46SHZWdmIxck1Sb0F1MEd4MUpjTWNsOEVwbkdjXzE3MTYzMDg3Mzc6MTcxNjMxMjMzN19WNA)

​                            Response Times Over Time (响应时间一直在增加)

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=YWQyMzFmODM0MDBiMzk1MjhkMmFkODljOWVkMWJkOGJfaVVkRm83SzBDbG41OEdpNkVRS2s4M3liZVpsa09YVWRfVG9rZW46T2lWUmI5RGFOb2dDbzV4dTd6V2NWb3ZYblJlXzE3MTYzMDg3Mzc6MTcxNjMxMjMzN19WNA)

​                         1C端查询桩群信息 tps不稳定  40并发 失败率太高(绿色失败>红色成功)

**2C端查询桩信息   20并发用户数**

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=OWQzMzE4OTRmNTcyOGQzODM2NGU0NjQxYTA5M2U2NThfMUJlRWw5Y29NRHNCam1YdUYwdXVHdGZKY0lCdWZ6MmpfVG9rZW46S2VFcWJGVkppb1BrRGl4VDlqQWM5WFdabjdjXzE3MTYzMDg3Mzc6MTcxNjMxMjMzN19WNA)

​                                   Response Times Over Time (响应时间一直在增加)

![img](https://wbenergy.feishu.cn/space/api/box/stream/download/asynccode/?code=M2Q3ZDgxMzEyZjY3NzYxYzRhZTIzMDdkOWQwYmY2ZDBfSUN5YVRyOXVZQjNMZU1NSUprMlZOU0ZXc2JVeWVSemhfVG9rZW46QUxVQWJMU3lTbzVEeDJ4UW56cWMwdTVVbkFkXzE3MTYzMDg3Mzc6MTcxNjMxMjMzN19WNA)

​                                tps不稳定  20并发 失败率太高



## 安卓测试

#### 安卓应用测试和web项目测试的区别与相同点

**安卓应用测试（移动应用测试）和Web项目测试（Web应用测试）**在测试的目的和基本理念上是相同的，都是为了保证软件质量，通过自动化或手动测试来发现缺陷、验证功能、性能和用户体验。但是，由于它们运行的平台和环境不同，测试的具体实施细节有所差异。

- #### 相同点：


1. **测试类型**：
   - 无论是安卓应用还是Web应用，都需要进行**功能性测试、界面测试、兼容性测试、性能测试、安全性测试**等。

2. **自动化工具**：
   - 可以使用自动化测试工具来减少重复工作，提高测试效率。例如，**Selenium 可用于Web自动化测试，而Appium 可用于安卓应用的自动化测试。**

3. **测试生命周期**：
   - 测试计划、用例设计、测试执行、缺陷跟踪和报告等阶段在两种测试中都很重要。

4. **质量保证**：
   - 目标是确保产品质量符合预期，通过测试来验证和确保产品满足用户需求。

5. **用户体验**：
   - **用户界面（UI）和用户体验（UX）**对于应用的成功至关重要，无论是Web应用还是安卓应用，测试都需要考虑这些方面。

- #### 区别：


1. **测试环境**：
   - 安卓应用测试通常需要在多种设备和操作系统版本上测试，以保证应用在不同设备和OS版本上的兼容性和性能。
   - Web项目测试则需要在不同的浏览器和操作系统上进行测试，确保Web页面在不同浏览器环境下的兼容性。

2. **交互复杂性**：
   - 安卓应用可能包含更复杂的用户交互，例如多点触控、传感器使用等，这些在Web应用中不太常见。

3. **安装和更新**：
   - 安卓应用需要在设备上安装和有时更新，测试需要考虑到安装过程和安装后的初次运行。
   - Web应用只需要通过浏览器访问，通常不需要安装过程，更新也由服务器端统一完成。

4. **资源和权限**：
   - 安卓应用测试需要考虑应用的权限请求、后台处理、系统资源（如内存和电量）的使用等。
   - Web应用测试通常关注于浏览器的资源占用，如内存泄漏等，并且受到浏览器沙箱模型的限制。

5. **网络状态管理**：
   - 安卓应用测试需要在各种网络状态下测试应用的行为和性能，包括离线状态、网络切换等。
   - 虽然Web应用测试也需要进行网络相关的测试，但一般假设用户是在线的，并且网络状态的变化不如移动设备上的那么频繁。

6. **分发渠道**：
   - 安卓应用可能通过Google Play、其他应用商店或APK直接分发，测试需要考虑不同的分发渠道。
   - Web应用只需要确保可以通过浏览器访问，没有安卓应用那样的分发问题。

7. **更新机制**：
   - 安卓应用的更新通常需要用户同意和下载，这意味着用户可能使用的是不同版本的应用。
   - Web应用的更新对用户来说是透明的，因为所有用户访问的都是服务器上的最新版本。

尽管安卓应用测试和Web项目测试在很多基本的测试概念和流程上是一致的，但是具体的测试实践、工具和方法由于平台和技术的不同而有所差异。在测试策略的制定和执行中，需要根据各自的特点和需求进行适当的调整。



## 游戏测试

![img](https://pic2.zhimg.com/v2-c46b7e26ed62cd0f46f77cb2fab125b1_r.jpg)

### 主要内容

<img src="C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231112135209638.png" alt="image-20231112135209638" style="zoom: 50%;" />

#### 弱网测试

弱网测试，或称为弱网络测试，是一种专门用于评估软件、尤其是移动应用和网络应用在网络条件不佳情况下的性能和稳定性的测试方法。在这种测试中，模拟各种不良网络条件，如低带宽、高延迟、丢包、网络波动等，以验证软件在这些条件下的响应和行为。

- #### 弱网测试的重要性

1. **真实用户体验：** 不是所有用户都会有理想的网络条件，特别是在移动网络环境中。
2. **健壮性和稳定性：** 确保应用在网络不稳定时仍然能够正常工作，不会导致数据丢失或其他严重问题。
3. **性能优化：** 有助于发现和优化在弱网环境下可能表现不佳的功能。
4. **保证应用稳定性**：确保在网络状况不佳时，应用依然可用且表现稳定。
5. **优化用户体验**：在**弱网环境下提供尽可能好的用户体验。**

- #### 弱网测试的常见场景

1. **低带宽测试：** 模拟网络带宽低于标准条件的情况。
2. **高延迟测试：** 模拟数据包传输的延迟增加的情况。
3. **丢包测试：** 模拟网络不稳定导致数据包丢失的情况。
4. **网络波动测试：** 模拟网络状态频繁变化的情况，如从4G切换到3G或Wi-Fi。

- #### 弱网测试的实施方法

1. **专业工具：** 使用网络模拟工具，如**NetLimiter**、**Charles Proxy**等，来模拟不同的网络条件。
2. **移动设备设置：** 在移动设备上直接设置或使用开发者选项来模拟弱网条件。
3. **场景模拟：** 创建特定的测试场景，以覆盖各种可能的网络问题。

- #### 弱网测试的关键指标

1. **应用响应时间：** 在弱网环境下应用的响应速度。
2. **数据完整性：** 确保在**网络不稳定时数据传输的完整性和准确性。**
3. **用户体验：** 应用在**弱网环境下的可用性和用户界面的响应性。**

通过弱网测试，**开发者可以确保他们的应用即使在不理想的网络条件下也能提供可靠的用户体验**。这种测试对于那些在不同地区和不同网络质量环境下被广泛使用的应用尤其重要。



#### GM工具测试

GM工具，即游戏管理员（**Game Master**）工具，是在多人在线游戏中使用的一套系统或软件工具，专为游戏的管理人员或运营团队设计。这些工具使游戏管理员能够监控游戏环境，管理玩家互动，处理技术或用户体验问题，执行特殊游戏事件，以及维护游戏的整体健康和平衡。

- #### GM工具的主要功能包括：

1. **玩家管理**：
   - 监控和管理玩家行为，包括警告、禁言、封号等处罚措施。
   - 解决玩家账户问题，如密码重置、账号恢复等。
2. **内容管理**：
   - 创建或修改游戏内的事件、任务、NPC（非玩家角色）等。
   - 调整游戏平衡，如物品掉落率、角色能力等。
3. **监控与报告**：
   - 监控游戏内的聊天和交易，以防止欺诈和不当行为。
   - 生成游戏运行相关的数据报告，如玩家活动、经济系统状况等。
4. **技术支持**：
   - 提供技术帮助，解决游戏中的错误和故障。
   - 执行数据恢复或调整以解决玩家的技术问题。
6. **安全和规则执行**：
   - 检测和防止作弊行为。
   - 确保玩家遵守游戏规则和行为准则。



- #### 举例说明：

假设你是一款**大型多人在线角色扮演游戏（MMORPG）**的管理员。你使用GM工具来监控游戏内的聊天室，以防止骚扰行为和滥用言论。此外，你还可以使用这些工具来调查玩家报告的错误，比如一个任务无法完成或某个物品无法使用。在处理了这些问题后，你可能还会通过工具创建一项特殊事件，比如临时增加游戏内物品的掉落率，以提高玩家的参与度和满意度。



#### SDK测试

SDK测试（Software Development Kit Testing）是指对软件开发工具包（SDK）的一系列测试，以确保其能够正常、高效地工作。SDK是一组软件工具和库，用于帮助开发者创建特定的软件应用程序。这些工具包可能包括文档、代码样例、进程说明、API（应用程序编程接口）等。

SDK测试的目的是确保SDK的每个组件都能按照预期工作，同时保证其与其他软件系统的兼容性。这种测试通常包括以下几个方面：

1. **功能测试**：检查SDK的各项功能是否都能按照设计正常运行。
2. **集成测试**：测试SDK与其他系统或模块的集成情况，确保它们能够协同工作。
3. **性能测试**：评估SDK在高负载或不同条件下的性能，包括响应时间和资源消耗。
4. **安全测试**：确保SDK中没有安全漏洞，防止潜在的安全威胁。
5. **兼容性测试**：确保SDK可以在不同的操作系统、硬件和软件环境中稳定运行。
6. **易用性测试**：评估SDK的用户界面和文档的清晰度，确保它们对开发者友好，容易使用。





### 不同类型游戏的测试要点

不同类型的游戏在测试时确实有着各自的重点和挑战。以下是针对几种常见游戏类型的测试要点概述：

**1. 动作游戏：**

- **响应性和控制精度**：测试**游戏控制是否精准、反应是否迅速。**

- **物理和碰撞检测**：确保游戏物理逼真，碰撞检测准确。

- **难度平衡**：游戏难度需适中，挑战性和可玩性平衡。

- **动画和视觉效果**：动画流畅，视觉效果符合预期。

  

**2. 角色扮演游戏（RPG）：**

- **故事和对话**：确保剧情连贯，对话无误。

- **角色发展和技能系统**：测试角色升级、技能树是否平衡。

- **任务和事件**：确保任务可完成，事件触发正确。

- **世界一致性**：游戏世界和背景故事保持一致。

  

**3. 策略游戏：**

- **AI行为**：确保AI行为逻辑、合理，提供适当的挑战。

- **资源管理**：资源系统平衡，没有明显的利用漏洞。

- **游戏规则和逻辑**：

- **界面和用户体验**：界面清晰，信息易于理解和访问。

  

**4. 模拟游戏：**

- **真实性和准确性**：**模拟效果逼真，符合预期。**

- **系统复杂性**：确保复杂的系统运行流畅，用户界面友好。

- **性能和稳定性**：模拟过程中保持性能稳定。

- **用户自定义和创造性**：**允许用户自由创造和定制。**

  

**5. 体育和赛车游戏：**

- **物理引擎**：**测试运动物理是否逼真。**

- **控制和反应性**：控制直观，反应灵敏。

- **比赛规则和裁判逻辑**：确保规则正确实施，裁判决策准确。

- **多人游戏**：测试**多人竞争和合作的流畅性。**

  

**6. 解谜和冒险游戏：**

- **逻辑和连贯性**：谜题和挑战逻辑上合理，可解。

- **故事叙述**：**故事情节连贯**，环节紧密相扣。

- **界面和指引**：提供清晰的用户界面和必要的游戏指引。

- **多结局和选择影响**：测试不同选择对游戏结局的影响。

  

**7. 多人在线游戏（MMO）：**

- **网络性能和稳定性**：确保游戏在**不同网络条件下稳定运行。**
- **社交和交互功能**：**测试聊天、团队和交易系统等功能。**
- **负载和压力测试**：**检查服务器在高负载下的表现。**
- **安全性和作弊防护**：确保游戏对作弊和攻击有足够的防护。



### 如何测试游戏中英雄的技能？

一、UI：技能的图标、描述、技能释放的动画效果 

  二、功能：技能的时间、技能的特效、技能的伤害、技能的交互、技能的音效、 

  三、场景：游戏场景：排位、匹配、娱乐；网络场景：2G/3G/4G/WiFi 

  四、专项：性能、弱网 

  1、技能的ui图标：局外的技能ui图标显示、局内的技能ui图标显示是否正常 

  2、技能的描述：局外的技能文字描述、局内的技能文字描述是否正确 

  3、技能的时间：局内技能的持续时间、释放时间、冷却时间是否正常 

  4、技能的特效：局内技能的特效显示是否正常，穿戴皮肤后的技能特效是否正常 

  5、技能的效果：技能的效果是否正常,如：治疗、出血、毒伤、暴击、防御、增伤、减伤。 

  6、技能的伤害：技能的伤害是否与技能描述的一致、局内伤害是否正常 

  7、技能的交互:技能和技能之间的交互是否正常，例如：B大招技能释放完，再释放A技能，可以减少B大招的冷却时间、 

  8、技能的施放：单次施放、多次施放是否正常 

  9、技能的音效：释放技能时，技能音效是否正常。 

  10、技能的动作：施放技能时动作是否流畅。 

  11、技能的升级：升级技能消耗的材料是否和实际消耗的一致、材料不足时，技能是否升级成功、材料充足时技能升级是否成功、技能升级后，伤害是否增加或减少、技能升级后的特效是否正常。快速点击技能，是否会发生异常：材料不足升级成功。 

  12、技能使用的场景：排位、匹配、娱乐、决斗场、 

  13、技能中断：释放技能是否会被友方或敌方的技能打断 

  14、技能的连接性：未释放完当前技能是否可以释放下一个技能。 

  15、装备对技能的影响：穿戴装备时、技能的释放速度、伤害数值、冷却时间是否变化正常。 

  16、药品对技能的影响：使用物品时，技能的释放速度、伤害数值、冷却时间是否变化正常。 

  17、技能的属性和连锁反应：技能的是否有属性攻击、无属性攻击；属性技能和其他属性技能产生的连锁反应：爆炸、融化、扩散、晶化、感电、蒸发、超导、点燃冻结、超载



### 如果游戏出现画面不流畅时，可能是哪些因素导致

游戏画面不流畅主要可能是由于硬件性能限制、软件优化不足或网络问题导致。以下是一些可能的原因以及相应的测试方法：

**可能的原因（客户端）：**

1. **硬件性能不足**：
   
   - **CPU或GPU性能不足，无法处理游戏的高图形需求。**
   - 内存不足，**导致游戏加载慢或频繁交换数据。**
- 存储速度慢（如使用HDD而非SSD），影响**数据加载速度。**
  
2. **软件优化问题**：
   - **游戏代码优化不足，导致资源无效利用。**
   - **图形设置过高，超出了硬件的处理能力。**
   - **驱动程序过时或不兼容。**

3. **网络问题**（在线游戏）：
   - **网络延迟或丢包。**
   - **服务器性能不足或服务器负载过高。**

4. **操作系统或背景应用程序**：
   - 操作系统问题或冲突。
- 运行在后台的应用程序占用过多资源。
  
5. **热量和散热问题**：
   
   - 电脑**过热导致性能降低。**
   
     

**硬件性能不足**

- **测试**：检查游戏所需的最低和推荐硬件配置，与你的系统配置进行比较。
- **解决**：**升级硬件（如CPU、GPU、RAM）或降低游戏的图形设置。**

**驱动程序过时**

- **测试**：检查显**卡和其他关键硬件的驱动程序是否为最新版本。**
- **解决**：更新硬件驱动。

**游戏设置过高**

- **测试**：将游戏的**图形设置（如分辨率、纹理质量、阴影效果）调整到较低水平。**
- **解决**：调整设置以找到最佳性能和视觉效果的平衡点。

**系统资源占用过高**

- **测试**：检查在运行游戏时其他应用程序或后台进程是否占用大量系统资源。
- **解决**：关闭不必要的应用程序和后台进程。

**网络问题**

- **测试**：如果游戏是在线的，检查网络延迟和丢包率。
- **解决**：优化网络连接，如使用有线连接、关闭其他占用带宽的应用等。

**操作系统问题**

- **测试**：**确保操作系统是最新的，检查是否有未安装的更新。**
- **解决**：更新操作系统。

**磁盘问题**

- **测试**：检查游戏安装的磁盘是否有足够空间，以及磁盘的读写速度是否正常。
- **解决**：清理磁盘空间，或将游戏安装在性能更好的磁盘上。



**测试方法：**

1. **硬件测试**：
   - 检查系统配置是否符合游戏的最低或推荐要求。
   - 使用**性能监控软件（如MSI Afterburner）**来观察CPU、GPU的使用率和温度。
   - 检查内存和存储性能。

2. **软件和图形设置**：
   - 降低游戏的图形设置，例如减少分辨率、关闭高级效果。
   - 确保使用最新的图形驱动和游戏补丁。
   - 检查是否有程序在后台运行，特别是资源密集型的应用程序。

3. **网络性能测试**（在线游戏）：
   - 使用网络速度测试工具检查互联网连接速度和稳定性。
   - 如果可能，尝试更换服务器或使用网络加速工具。

4. **操作系统和软件冲突**：
   - 确保操作系统更新至最新。
   - 在干净的启动环境中运行游戏，以排除软件冲突的问题。

5. **散热和温度监控**：
   - 使用硬件监控工具检查PC的温度。
   - 确保散热系统（如风扇和散热器）工作正常。



**可能的原因（服务端）：**

1. **服务器性能不足**

- **如果服务器处理能力不足，可能会导致游戏响应缓慢**。这在玩家数量众多、服务器负载高峰时尤为明显。
- 服务器的CPU或内存资源不足会导致处理玩家请求的延迟，这可能表现为游戏中的动作延迟或卡顿。

1. **网络延迟和稳定性问题**

- 网络延迟（Ping值高）或丢包会影响服务器与客户端之间的数据同步，导致游戏中出现“跳帧”或短暂卡顿。
- 如果服务器的网络连接不稳定，玩家可能会经历断线、重连等问题，这会直接影响游戏体验的流畅性。

1. **服务器软件和数据库问题**

- 服务器上运行的游戏软件可能存在优化不足或错误，导致处理效率低下。
- 数据库查询效率低下或数据库过载也可能导致游戏中的数据加载和处理延迟。

1. **服务器配置和维护**

- 错误的服务器配置可能会限制游戏性能。
- 服务器没有得到适当的维护（例如，定期重启以释放资源），可能会随时间积累性能问题。



**测试服务器相关问题的方法：**

1. **监控服务器性能**：监控CPU、内存、网络带宽的使用情况，以检测瓶颈。
2. **网络延迟测试**：通过Ping和Traceroute测试来检测到服务器的网络延迟和路径稳定性。
3. **服务器日志分析**：检查服务器日志，寻找错误或警告信息，这可能表明了性能问题或故障点。
4. **压力测试**：模拟高负载情况，看服务器如何应对大量并发请求。
5. **玩家反馈**：收集和分析玩家的反馈，尤其是关于游戏流畅性和连接问题的反馈。



### 手机游戏 VS PC游戏

#### 手机

**1. 功能测试**

- **基本功能**：确保游戏的所有基本功能，如游戏开始、暂停、保存、加载、得分系统等，都按预期工作。
- **界面测试**：检查用户界面元素在不同设备上的显示和响应情况，包括按钮大小、文本可读性等。

**2. 兼容性测试**

- **多平台测试**：测试游戏在不同操作系统（如iOS、Android）和版本上的兼容性。
- **设备多样性**：测试游戏在不同品牌、屏幕尺寸和硬件配置的手机上的性能。

**3. 性能测试**

- **资源消耗**：监测游戏运行时对手机资源的消耗，包括CPU、内存、电池等。
- **网络性能**：对网络依赖的游戏，测试不同网络条件（如Wi-Fi、4G、5G）下的性能。

**4. 用户界面和用户体验测试**

- **触控响应**：测试触摸屏幕的响应速度和准确性。
- **视觉和音频元素**：确保视觉和音频元素在不同设备上保持一致性。

**5. 安全性和隐私测试**

- **数据安全**：确保游戏中的**用户数据安全，特别是支付和个人信息。**
- **权限使用**：检查游戏对手机权限的请求是否适当。

**6. 本地化测试**

- **语言支持**：对游戏的多语言支持进行测试，确保翻译准确，文本布局适当。

**7. 自动化测试**

- **开发或使用自动化工具**：利用**自动化测试框架（如 Appium、Selenium）来提高测试效率**。

**8. 实际用户测试**

- **Beta测试**：通过实际用户进行Beta测试，**收集反馈，特别关注用户体验和游戏平衡性。**



#### PC

**1. 硬件和配置兼容性**

- **更广泛的硬件兼容性测试**：PC有更多种类的硬件配置，包括不同的CPU、GPU、内存和存储设备。
- **图形和性能设置**：测试游戏在不同的图形设置下（如分辨率、纹理质量、阴影等）的性能和稳定性。

**2. 操作系统兼容性**

- **多操作系统测试**：除了测试不同版本的Windows，还可能需要测试其他操作系统，如Linux或MacOS。
- **驱动程序兼容性**：确保游戏与常见的显卡和音频驱动程序兼容。

**3. 控制和输入设备**

- **多样化的输入设备**：测试游戏对键盘、鼠标、游戏手柄等不同输入设备的支持。
- **可定制的控制设置**：确保游戏允许玩家自定义控制设置。

**4. 网络测试**

- **多玩家游戏的网络性能**：对于支持多人在线的游戏，网络连接的稳定性和性能尤为重要。

**5. 安装和更新**

- **安装过程**：测试游戏的安装过程是否顺利，包括文件的解压和安装路径的选择。
- **更新和补丁**：确保游戏更新和补丁的应用不会引入新的问题。

**6. 用户界面和用户体验**

- **分辨率和屏幕比例**：测试游戏在不同分辨率和屏幕比例下的表现，包括全屏和窗口模式。
- **可访问性选项**：例如，对视觉障碍或听力障碍玩家的支持。

**7. 安全性和反作弊**

- **反作弊机制**：在PC平台上，反作弊机制的重要性更高，特别是对于在线多人游戏。

**8. 性能测试和优化**

- **系统资源消耗**：监测游戏对PC资源（CPU、GPU、内存）的消耗。
- **热量和噪音管理**：在高性能要求下测试硬件的热量和噪音水平。

**9. 自动化和脚本测试**

- **更复杂的自动化测试**：由于PC游戏的多样性和复杂性，**自动化测试可能需要更高级的脚本和工具。**

**10. 社区和模组支持**

- **模组和社区内容**：对于支持模组的游戏，测试模组的兼容性和影响。

  

### 测试过程

**步骤1：理解游戏需求和功能** 首先，你需要深入了解游戏的需求和功能。**这包括游戏的规则、游戏性、目标、角色、物品、关卡设计等等**。与游戏开发团队密切合作，以确保你对游戏的功能有全面的了解。

**步骤2：确定测试类型** 游戏测试可以包括多种类型，如**功能测试、性能测试、兼容性测试、用户界面测试**等。根据游戏的性质和需求，确定测试类型。例如，如果游戏是一个多人在线游戏，那么网络性能可能是一个关键因素，需要进行性能测试。

**步骤3：制定测试策略** 制定一个**测试策略，包括测试的范围、优先级和时间表。**确定哪些部分需要优先测试，哪些可以稍后测试。

**步骤4：编写测试用例** 现在开始编写测试用例。每个测试用例应该包括以下要素：

- **测试名称**：简洁描述测试的名称。
- **测试描述**：详细描述**测试的目标和步骤。**
- **预期结果**：描述测试成功的标准。
- **先决条件**：描述运行测试所需的**前提条件**，例如特定的游戏状态或设置。

测试用例应该尽可能全面地覆盖游戏的各个方面。例如，如果你正在测试一个角色扮演游戏，**可以编写测试用例来验证角色的动作、对话、装备、技能等各个方面。**

**步骤5：执行测试用例** 按照编写的测试用例执行测试。**确保按照预期结果来验证每个测试，记录任何发现的问题或错误**。

**步骤6：记录和报告问题** 当你在测试过程中发现问题时，**要详细记录问题的描述、复现步骤和问题的严重程度**。然后，将问题报告给游戏开发团队，以便他们可以修复问题。

**步骤7：回归测试** 一旦问题得到修复，**进行回归测试**，确保修复不会引入新问题或导致其他功能失效。

**步骤8：重复测试周期** 游戏测试是一个迭代的过程，通常需要多次重复上述步骤，直到游戏达到满意的质量水平。

**步骤9：最终验收测试** 最终验收测试是确保游戏符合要求并准备发布的最后一步。在这个阶段，需要验证游戏是否满足了所有的功能和性能要求。



### 游戏性能测试

**1. 帧率（FPS）**

- **定义**：每秒渲染的帧数。较高的帧率可以提供更平滑的视觉体验，有助于提高玩家对游戏的反应速度。
- **理想值**：通常，60 FPS被认为是流畅游戏体验的标准，但某些游戏和高端显示设备可能会追求更高的帧率，如120 FPS或更高。

**2. 输入延迟（Input Latency）**

- **定义**：玩家操作到游戏响应（如角色移动、射击等）之间的时间延迟。
- **优化目标**：尽量减少输入延迟，以便玩家操作能够即时反映在游戏中。

**3. 网络延迟（Ping/网络延迟）**

- **定义**：在线游戏中，玩家的机器与游戏服务器之间的**通信延迟。**
- **理想值**：较低的网络延迟（通常以毫秒计）对于多人在线游戏至关重要，理想值低于100毫秒，对于竞技游戏可能需低于50毫秒。

**4. 显示延迟（Display Latency）**

- **定义**：显示**设备渲染图像的延迟时间。**
- **优化目标**：使用**具有较低显示延迟的显示器，**尤其是对于需要快速反应的游戏。

**5. 帧时间（Frame Time）**

- **定义**：渲染每一帧所需的时间。
- **优化目标**：稳定的帧时间有助于避免画面卡顿和不稳定，即使帧率较高，不稳定的帧时间也会影响游戏体验。

**6. 资源使用率（如CPU和GPU使用率）**

- **定义**：游戏运行时CPU和GPU的使用率。
- **优化目标**：确保游戏代码高效运行，避免不必要的资源浪费，以免造成性能瓶颈。

**7. 内存和磁盘I/O**

- **定义**：游戏对系统内存的使用以及对磁盘的读写速度。
- **优化目标**：优化内存管理和数据加载，以减少卡顿和加载时间。



### 游戏测试和软件测试的区别

游戏测试和软件测试在很多方面是相似的，因为它们都是**确保产品质量的活动**，都包括查找和报告错误，以及验证功能是否按照预期工作。不过，它们之间也存在一些关键的区别，**主要体现在测试的焦点、测试方法、所需技能和最终目标上。**

**游戏测试的特点：**

1. **用户体验重心**： 游戏测试不仅要确保游戏无缺陷，还要关注游戏的**可玩性和娱乐性**。这包括游戏的**故事情节、画面、音效、操作手感和整体用户体验。**

   - **UI&&UE**

   **大部分软件UI&&UE的重要性没有游戏那么高，在玩游戏的过程中，愉悦感和趣味性是至关重要的，如果缺失了这些要素，用户可能瞬间就流失了，也就意味着这款游戏失败了。**

   - **数值**

   数值对游戏至关重要，无论单机还是网络游戏，**玩家非常重视自己角色的数值增长**。**游戏功能之间的耦合度非常高，数值之间有着千丝万缕的关联，而软件功能之间的耦合度则没有这么高，很多情况下功能之间的数值是相对独立的。**

   - **活动**

   游戏中，活动则是频度更高的一种玩法，测试过程中受到的关注度更高，**游戏活动的测试更关注时间与资源产出**，活动衔接也很重要，任何差错都可能导致更大的损失，而软件上的活动则没这么严格的概念。

    

2. **配置和平台多样性**： 游戏通常**需要在多种硬件配置、游戏平台（如PC、游戏机和移动设备）上进行测试，**以确保所有玩家都有良好的体验。

   

3. **性能测试**： 游戏测试需要密切**关注性能，包括帧率、加载时间、内存使用情况等**，特别是在不同的硬件配置上。

   **性能测试**对游戏至关重要，无论在台式还是移动设备，卡顿会让玩家厌恶。为确保游戏流畅，客户端内存和cpu使用率在游戏测试中都要重视。而且用户的设备差异性很大，尤其是移动端。所以我们必须确保客户端的性能符合我们的预期标准。软件则没太多这方面的需求。

   - **网络**

   网络对于网络游戏和软件都是必不可少的，但游戏的实时交互性比较高。所以对网络的测试要求也比较高，因为不同的网络运营商，不同地区的网络信号，甚至移动过程中不同网络的切换，这些都需认真测试，这样才能更好的提高用户体验度。

   

4. **交互性测试**： **游戏往往具有高度的交互性，测试人员需要检查游戏控制的响应性以及用户界面的直观性。**

   大多针对网游，网游中很大程度的乐趣都来源于**玩家与玩家之间的交互**，传统软件（忽略社交软件而言）中并不多见。玩家交互的越频繁**，数据之间交互的程度越高，数据之间的复杂变换及相互影响需时刻关注。**

5. **安全性测试**： 尽管游戏的**安全性测试**不像某些软件那样关键，但游戏测试人员仍需确保游戏数据不会被恶意用户篡改。



**软件测试的特点：**

1. **功能性重心**： 软件测试更注重应用的**功能性和稳定性**。它关注的是软件是否能够按照规格文档完成所需的任务。

2. **兼容性和集成测试**： 软件测试需要考虑软件如何与不同的操作系统、数据库、其他软件等集成和交互。

3. **自动化测试**： 在软件测试中，**自动化测试**占据了很大一部分，**因为许多功能测试可以通过脚本或自动化工具重复执行。**

4. **安全性和合规性**： 对于软件，尤其是**涉及个人数据和商业操作的应用，安全性和合规性是测试的重要方面。**

5. **文档和流程**： 软件测试往往更注重文档记录，遵循严格的质量保证流程，这对于维护、审计和合规性非常重要。

   



### 游戏开发过程中需要测试的地方

**1. 概念阶段（Concept Stage）**

- **理念可行性测试**：评估游戏的基本概念和设计对目标受众的吸引力。

**2. 原型阶段（Prototyping Stage）**

- **游戏机制测试**：确保基础游戏机制是有趣且可玩的。
- **控制测试**：检查控制方案是否直觉且响应迅速。

**3. 开发阶段（Development Stage）**

这一阶段涵盖了大部分的测试工作，包括但不限于：

- **单元测试**：针对游戏中的小型功能块，如类或函数，进行测试。
- **集成测试**：确保多个组件或系统（如物理引擎与游戏逻辑）能够一起正常工作。
- **系统测试**：测试整个游戏系统的功能，确保所有元素作为一个整体能够协同工作。
- **性能测试**：确保游戏**在各种硬件上运行流畅，没有内存泄漏、过度的CPU或GPU使用**等问题。
- **界面测试**：测试用户界面的所有方面，包括布局、导航、可读性和易用性。
- **兼容性测试**：确保游戏可以在所有支持的平台和设备上运行。
- **网络测试**：对于多人在线游戏，测试网络连接、同步、延迟和数据包丢失情况的处理。
- **AI测试**：如果游戏包含AI，确保它的表现符合预期。

**4. Alpha和Beta测试阶段**

- **Alpha测试**
  - **功能完整性测试**：确保所有游戏功能已实现并可用。
  - **错误修复验证**：验证先前识别的错误是否已正确修复。
- **Beta测试**
  - **玩家体验测试**：真实玩家测试游戏并提供反馈。
  - **压力测试**：确保游戏服务器可以处理大量玩家。
  - **平衡测试**：调整游戏平衡，确保没有过强或过弱的元素。

**5. 发行前和发行后**

- **回归测试**：在每次新的游戏版本发布前进行，以确保新添加或修改的内容没有引入新的错误。
- **验收测试**：在游戏发布前，确认游戏符合所有发布标准和要求。
- **后发行测试**
  - **补丁验证**：确保**发布的补丁解决了正确的问题且没有引入新的问题。**
  - **更新和迭代测试**：对于新的内容更新或游戏迭代进行测试。



### 为什么选择做游戏测试

1. **对游戏的热爱**：许多游戏测试员从对游戏的热情出发，他们喜欢玩游戏，并希望将其作为职业生涯的一部分。
2. **行业入门**：对于希望进入游戏行业的人来说，游戏测试是一个相对易于入门的职位。它为初学者提供了了解游戏开发流程的机会，并可能成为晋升到游戏设计、开发或项目管理等其他职位的跳板。
3. **技能提升**：游戏测试不仅仅是玩游戏，**它还涉及到分析、批判性思维和沟通等技能**。对于那些想要在这些领域提升自己能力的人来说，游戏测试是一个很好的开始。
4. **质量保证的满足感**：**游戏测试员通过确保游戏产品的质量，为最终用户提供无缺陷的游戏体验，从中获得满足感。**
5. **工作环境**：游戏公司通常**提供创意和富有活力的工作环境**。对于希望在较少正式的、更具创造性的工作场所工作的人来说，这是一个吸引人的选项。
6. **职业发展**：游戏测试经验可以**为个人提供深入了解游戏开发各个方面的机会**，这对于长期职业规划非常宝贵。
7. **团队合作**：在游戏测试的工作中，**有机会与开发者、艺术家、声音工程师等各种角色的团队成员合作，这对于喜欢在团队中工作的人来说是一个重要因素。**
8. **持续学习**：**游戏行业是一个快速发展的领域**，游戏测试员需要**不断学习新技术、新工具和新流程**，这对于有志于终身学习的人来说非常有吸引力。



## 真实测试例题

### 存在数量限制处理数据库并发问题

在处理类似于购物需求的场景，特别是当存在数量限制（如商品只有50个）时，确保下单数量不超过库存是关键。在多线程环境中，这种需求需要考虑线程安全和同步机制，以防止数据竞争和条件竞争造成的问题。以下是一些步骤和考虑因素：

**1. 使用线程安全的数据结构和同步机制**

- **锁（Locks）**：使用锁来确保一次只有一个线程可以访问和修改共享资源（如库存数量）。
- **原子操作**：在某些编程语言中，可以使用原子操作来保证增减库存的操作不会被线程中断。
- **信号量（Semaphore）**：利用信号量来限制可以访问特定资源的线程数量。

**2. 检查库存和处理订单**

在处理每个下单请求时，你需要执行以下步骤：

1. **锁定库存数量**：在检查和修改库存之前，确保获取锁。
2. **检查库存**：确认是否有足够的库存满足当前订单。
3. **处理订单**：
   - 如果库存充足，减少库存数量，并继续处理订单。
   - 如果库存不足，拒绝订单或将其标记为等待补货。
4. **释放锁**：完成库存检查和修改后，释放锁，允许其他线程访问。

**3. 实例代码示例（假设使用Python）**

假设你正在使用Python，可以使用`threading`模块来实现这一需求。下面是一个简化的示例：

```python
import threading

class Inventory:
    def __init__(self, stock):
        self.stock = stock
        self.lock = threading.Lock()

    def process_order(self):
        with self.lock:
            if self.stock > 0:
                self.stock -= 1
                print("Order processed, remaining stock:", self.stock)
            else:
                print("Out of stock!")

inventory = Inventory(50)

def thread_function():
    for _ in range(10):  # 假设每个线程处理10个订单
        inventory.process_order()

threads = []
for i in range(10):  # 创建10个线程
    thread = threading.Thread(target=thread_function)
    thread.start()
    threads.append(thread)

for thread in threads:
    thread.join()
```

在这个例子中，`Inventory` 类使用一个锁来保护库存数量。每当一个线程尝试处理订单时，它首先需要获得锁，这确保了在检查和修改库存时不会有其他线程干扰。

**4. 考虑并发和性能**

- **避免死锁**：确保设计中不会出现死锁情况。
- **优化性能**：过多的锁可能会导致性能问题。需要权衡锁的使用和系统的响应速度。

**5. 数据库事务**

如果订单和库存数据存储在数据库中，还可以使用数据库事务来确保数据的一致性。大多数数据库管理系统支持事务，它可以确保一系列操作要么全部完成，要么全部不做，这对于避免库存超卖非常有效。



### **请问对一个协调游戏进行同步性测试应该怎么做？ 我应该怎么写测试代码？**

**1. 明确测试目标**

- 确定你要测试的同步方面，比如延迟、数据包丢失、状态同步一致性等。

**2. 选择或构建测试框架**

- 使用现有的网络测试工具，如Wireshark、Unity Test Framework等。
- 构建自定义测试框架，特别是当游戏具有独特的同步机制时。

**3. 设计测试用例**

- **延迟测试**：发送数据包，并测量其从发送到被接收的时间。
- **数据一致性测试**：确保所有玩家看到相同的游戏状态。
- **压力测试**：模拟高负载情况下的网络环境和玩家活动。

**4. 编写测试脚本**

- 使用游戏开发平台提供的脚本语言（如C# for Unity）。
- 脚本应包括发送、接收数据包，记录时间戳，以及状态验证等功能。

**5. 模拟网络环境**

- 使用工具如Clumsy来模拟网络延迟、丢包等情况。
- 编写脚本来自动改变网络条件，模拟不同玩家的网络环境。

**6. 自动化测试**

- 利用脚本自动化重复的测试过程。

- 使用模拟玩家（Bots）进行游戏，以测试不同的同步场景。

  > #### 使用模拟玩家（Bots）进行测试
  >
  > 1. **设计Bots**: 这些Bots应能模拟真实玩家的行为，包括移动、执行任务、响应游戏事件等。
  > 2. **程序控制**: Bots应通过脚本完全控制，以确保它们的行为可以预测和重复。
  > 3. **多场景测试**: 设计不同的游戏场景和条件，让Bots在这些环境下运行，以测试游戏的同步机制。
  >
  > #### 编写自动化测试脚本
  >
  > 1. **语言选择**: 根据你的游戏开发环境选择合适的编程语言，如C#（Unity），Python等。
  > 2. **功能实现**: 脚本需要能够启动游戏，控制Bots行为，记录测试结果，以及在测试结束后关闭游戏。
  > 3. **网络模拟**: 通过脚本模拟不同的网络条件，如延迟、带宽限制、数据包丢失等。
  >
  > #### 测试案例设计
  >
  > 1. **延迟和丢包测试**: 检查游戏在高延迟或高丢包率下的表现。
  > 2. **并发测试**: 同时运行多个Bots，测试游戏在高并发情况下的同步性能。
  > 3. **状态一致性**: 确保所有Bots在任何给定时刻都看到一致的游戏状态。

**7. 性能监测**

- 监控网络流量、CPU和内存使用情况，以评估同步机制的效率。

**8. 结果记录与分析**

- 自动记录测试结果，比如延迟时间、状态不一致的实例等。
- 分析这些数据，找出可能的同步问题和性能瓶颈。

**9. 用户体验测试**

- 在测试环境中加入真实玩家，收集他们的反馈。

**10. 持续集成和反复测试**

- 将测试集成到开发流程中，确保每次更新后都进行测试。

> ### **游戏状态同步问题中的数据包应该如何获得，如何检查它的完整性和时效性**
>
> #### 获取数据包
>
> 1. **网络抓包工具**：
>    - 使用像Wireshark这样的网络抓包工具来捕获在游戏客户端和服务器之间传输的数据包。
>    - 配置抓包工具以侦听特定的端口或使用过滤器来专注于游戏数据包。
> 2. **游戏客户端和服务器日志**：
>    - 在开发阶段，可以在游戏客户端和服务器上实现日志记录功能，以记录发送和接收的数据包信息。
>    - 这些日志可以提供数据包的详细信息，如时间戳、大小和内容。
>
> #### 检查数据包的完整性
>
> 1. **数据包结构分析**：
>    - 确认数据包是否遵循预定的格式和结构。这可能包括检查数据包的头部、载荷和尾部。
>    - 验证数据包是否包含所有必要的信息，如玩家ID、动作代码和游戏状态数据。
> 2. **完整性校验**：
>    - 使用校验和或其他完整性校验方法来确认数据包在传输过程中没有被损坏。
>    - 对比发送端和接收端的数据包内容，确认一致性。
>
> #### 检查数据包的时效性
>
> 1. **时间戳分析**：
>    - 检查数据包的时间戳。时间戳通常在数据包发送时附加，以记录数据包的确切发送时间。
>    - 比较发送和接收时间戳，计算延迟。
> 2. **性能指标**：
>    - 使用延迟、丢包率等网络性能指标来评估数据包的时效性。
>    - 在不同网络条件下测试，比如模拟高延迟或高丢包环境。

> 假设我们有一个在线多人射击游戏，其中玩家可以移动和射击。以下是一个典型的数据包结构示例，用于玩家射击动作的同步：
>
> ##### 示例：玩家射击动作的数据包
>
> 1. **数据包头部（Header）**：
>    - **Packet ID**：唯一标识数据包类型的ID，例如`0x01`表示射击动作。
>    - **Timestamp**：数据包生成的时间戳，用于确定延迟和同步，例如`1653012345`。
>    - **Player ID**：执行射击动作的玩家ID，例如`Player123`。
>    - **Sequence Number**：数据包的序列号，用于检测丢包和顺序，例如`1024`。
> 2. **数据包载荷（Payload）**：
>    - **Position**：玩家射击时的位置坐标，例如`{x: 100, y: 50, z: 20}`。
>    - **Direction**：射击方向的向量，例如`{dx: -1, dy: 0, dz: 0}`。
>    - **Weapon ID**：使用的武器类型，例如`Rifle01`。
>    - **Action Timestamp**：执行射击动作的确切时间，用于更精确的同步，例如`1653012345.678`。
> 3. **数据包尾部（Footer）**：
>    - **Checksum**：用于验证数据包完整性的校验和，例如`0x9AFC`。
>
> ##### 数据包的检查和分析
>
> 1. **完整性检查**：
>    - 校验数据包头部和尾部的完整性。确保序列号和校验和正确无误。
>    - 确认载荷中的所有数据（位置、方向、武器ID等）都按预定格式完整传输。
> 2. **时效性检查**：
>    - 分析时间戳。比较数据包的生成时间戳（Header中的Timestamp）和执行动作的时间戳（Payload中的Action Timestamp）与服务器接收到数据包的时间，来计算网络延迟。
>    - 使用序列号来检测丢包和数据包的到达顺序。

- ### **针对moba游戏和多人竞技游戏的游戏中战斗测试可能包括什么内容**

1. **功能性测试**:

   - 测试游戏中的战斗系统是否按预期工作，包括角色技能、攻击、防御、移动等。
   - 验证所有战斗相关元素（如武器、装备、技能）的功能正确性。

2. **平衡性测试**:

   - 确保游戏中的各个角色、技能和装备在战斗中平衡，无过强或过弱之处。
   - 测试不同组合的策略和技能在实战中的表现，确保公平竞争。

3. **性能测试**:

   - 测试游戏在不同硬件和网络条件下的性能，确保战斗场景中的流畅体验。
   - 检查高强度战斗时的帧率和延迟情况。

4. **用户界面（UI）测试**:

   - 确保战斗相关的用户界面（如生命值、技能冷却等）显示正确且易于理解。
   - 测试战斗时的UI响应性和可用性。

5. **网络和多玩家交互测试**:

   - **测试游戏在多人在线环境下的稳定性，包括服务器负载和网络延迟对战斗的影响。**
   - 检查多玩家交互、团队协作和对战机制的功能性。

6. **AI和非玩家角色（NPC）行为测试**:

   - **测试游戏AI的表现，确保NPC在战斗中的行为符合设计。**
   - 检查敌对AI的挑战性和适应性。

7. **边缘情况和异常测试**:

   - 测试极端情况下的游戏表现，如非常规战斗策略或罕见技能组合的影响。
   - 检测和修复可能导致游戏崩溃或错误的异常情况。

8. **声音和图形测试**:

   - 确保战斗中的声音效果和视觉效果符合设计标准，增强沉浸感。
   - 测试特效和动画在不同系统上的表现和一致性。

9. **可访问性测试**:

   - 确保战斗系统对不同能力的玩家友好，包括可定制的控制选项和辅助功能。

     

- ### 使用chatgpt如何帮助我们进行游戏测试


1. **数据分析与建议**：
   - **分析游戏数据：如果您提供具体的游戏数据（如角色的属性、技能数据、战斗记录等），我可以帮助分析这些数据，提出可能的最优化策略。**
   - 性能对比：对比不同角色或装备的性能，帮游戏中战斗测试可能包括什么内容助您做出更合理的选择。
2. **理论模拟与策略规划**：
   - **角色搭配与团队构建**：基于角色的技能和属性，提供理论上的最佳队伍搭配和战术规划。
   - **伤害计算与优化**：协助进行伤害输出的理论计算，帮助您优化角色构建。
3. **信息汇总与研究**：
   - **游戏资料收集**：提供游戏的最新信息、攻略、更新内容等。
   - 研究社区反馈：搜集和分析游戏社区的反馈和讨论，帮助您了解广大玩家的观点和策略。
4. **问题解答与建议**：
   - 解答疑问：针对游戏中的特定问题提供解答和建议。
   - 技巧分享：分享一些游戏技巧和小窍门，提升游戏体验。
5. **编程与自动化**：
   - **自动化脚本建议**：如果您有编程背景，我可以提供一些编写自动化测试脚本的建议。
   - 数据分析工具：建议使用特定的数据分析工具或方法来处理游戏数据。



### 请问如果我希望测试原神里一个新出的角色，请问可能从什么角度进行测试？

1. **基本属性与技能分析**：
   - **生命值、攻击力、防御力**：测量这些基本属性在不同等级下的变化。
   - **元素属性**：假设角色是一个水元素角色，观察其元素技能如何与其他元素（如火、雷）互动。
   - **主动技能与元素爆发**：检查技能的伤害、范围、冷却时间。例如，如果角色有一个造成范围水元素伤害的技能，测试这个技能在单独使用和与其他元素反应时的效果。
2. **战斗表现与效能测试**：
   - **单体与群体伤害**：在不同敌人（单个和群体）上测试角色的伤害输出。
   - **元素反应**：实验角色的水元素技能与其他元素（如火造成蒸发反应）的结合效果。
   - **支援能力**：如果角色具有治疗或增益技能，测试这些技能在不同团队配置中的效果。
3. **装备与构建探索**：
   - **武器兼容性**：测试不同类型的武器（如长剑、弓）对角色攻击效率的影响。
   - **圣遗物选择**：尝试不同的圣遗物套装（如增强攻击力、元素充能效率），以确定最优搭配。
4. **操作与可玩性评估**：
   - **操作难易度**：评估角色的技能激活和连招操作的难易程度。
   - **角色定位**：根据技能和属性，判断角色是否适合作为主DPS、辅助或其他角色。
5. **团队配合与协同效果测试**：
   - **搭配其他角色**：将角色放入不同的团队组合中，测试其与其他角色（如火元素角色进行蒸发反应）的**协同作战效果**。
   - **不同环境适应性**：在不同的游戏区域和针对不同类型的敌人测试角色的表现。
6. **特殊能力与独特机制探索**：
   - **独特技能测试**：如果角色有独特的**技能机制**（如特殊的元素吸收或反射），**在各种情境下测试这些技能的实际应用**。



**《逃跑吧！少年》**

- **核心玩法和特点**

1. **非对称对抗玩法**：这种类型的游戏通常包括两组角色，各自拥有不同的目标和能力。在这款游戏中，玩家可以选择扮演“逃生者”或“追捕者”，两者的目标和策略完全不同。这种设置创造了一个多样化的游戏体验，每个角色都提供了不同的挑战和乐趣。
2. **逃生者角色**：作为逃生者，玩家需要通过躲藏、变身、火拼等方式躲避追捕者。这要求玩家具备策略思维和快速反应能力。团队合作在此过程中扮演着重要角色，玩家需要协作寻找钥匙并最终逃生。
3. **追捕者角色**：扮演追捕者时，玩家的任务是**找到并阻止逃生者逃跑**。这需要玩家具备良好的搜寻技巧和战术规划能力。追捕者在游戏中扮演“反派”角色，为游戏增添了紧张和刺激的元素。
4. **环境和动态元素**：游戏中包括精彩的动作、追车和爆炸场面，这些元素不仅提升了游戏的视觉效果，也增加了游戏的紧迫感和动态感。这样的环境设置使得每一轮游戏都充满不确定性和惊喜。
5. **互动和娱乐性**：游戏鼓励玩家**奔跑、跳跃、战斗并互相伤害**，这增加了游戏的互动性和娱乐性。轻松诙谐的**对抗**乐趣使得这款游戏不仅适合竞技玩家，也适合寻求休闲娱乐的玩家。

总体来说，《逃跑吧！少年》是一款结合策略、团队协作、动作和娱乐的游戏，适合各种类型的玩家。其非对称对抗的核心玩法提供了丰富的游戏体验，并能够吸引不同兴趣和技能水平的玩家。



- **请问如果测试这个游戏，可以从什么角度进行测试？**
  1. **功能测试**：
     - 验证所有游戏功能**是否按预期工作，如角色选择、游戏模式、得分系统等。**
     - 检查游戏内各种互动元素（如躲藏、变身、火拼）是否正常工作。
  2. **用户界面和可用性测试**：
     - 确保游戏界面直观易用，信息展示清晰。
     - 测试导航流程是否流畅，如菜单、设置、游戏匹配等。
  3. **性能测试**：
     - 检查游戏在不同硬件和网络条件下的性能，包括帧率、加载时间等。
     - 测试游戏在高负载下（例如多玩家同时在线）的稳定性。
  4. **网络测试**：
     - 验证多玩家在线互动时的网络稳定性和延迟情况。
     - 测试游戏的**同步机制**，**确保所有玩家看到的游戏状态一致。**
  5. **平衡性测试**：
     - 确保“逃生者”和“追捕者”之间的平衡，无明显优劣势。
     - 测试不同角色和技能的组合，确保没有过强或过弱的配置。
     - **地图设计测试**：游戏地图应该为两方提供平等的机会。需要测试地图上的各种元素，如藏身处、障碍物、逃生路径等，以确保它们不会偏向任何一方。
  6. **安全性和合规性测试**：
     - 检查游戏是否有潜在的安全漏洞，如数据泄露、作弊等。
     - 确保游戏内容符合相关法律法规，特别是针对未成年玩家的内容限制。
  7. **兼容性测试**：
     - 测试游戏在不同操作系统、设备、分辨率上的兼容性。
     - 确保游戏在各种配置下都能正常运行。
  8. **负载和压力测试**：
     - 模拟**高流量和高使用量情况**，**测试游戏服务器的承载能力**。
     - 检查在极端条件下游戏的响应时间和稳定性。
  9. **声音和图形测试**：
     - 确保游戏中的声音效果和图形渲染符合设计标准。
     - 测试在不同音频和视频设置下的表现。
  10. **可访问性测试**：
      - 确保游戏对于不同能力的玩家是可访问的，包括颜色盲模式、字幕选项等。



1. **团队协作机制**：由于游戏强调团队合作，需要测试玩家之间的协作机制，包括通信工具的有效性和团队策略的实施。
2. **匹配系统**：测试游戏的**匹配系统**，确保玩家被正确地匹配到相似技能水平的对手。
3. **隐蔽和伪装机制**：特别检查逃生者使用的躲藏和变身机制是否有效且公平。
4. **追捕和捕捉机制**：验证追捕者的搜索、追捕和捕捉机制是否顺畅且有效。
5. **游戏环境交互性**：测试玩家与游戏环境的交互，包括物体的**可破坏性、陷阱的布置**等。
6. **逃生和救援机制**：检查逃生门的机制以及被关押逃生者的救援流程是否有逻辑性和公平性。
7. **特殊道具和技能的平衡**：如果游戏中有特殊道具或技能，需要测试它们的影响是否平衡，不会使某一方过于强大。
8. **心理和压力元素**：考虑到游戏的紧张性和激烈性，测试游戏设计对玩家心理的影响，确保游戏体验既刺激又不过度压抑。
9. **游戏节奏和时长**：测试整体游戏的节奏和**单局游戏的持续时间**，以确保它们符合预期的游戏体验。
10. **作弊和反作弊措施**：特别注意游戏的作弊潜力和**实施有效的反作弊措施。**



### 项目：Selenium，Unittest和HtmlTestRunner

以下是一个**使用 Selenium、Unittest 和 HtmlTestRunner** 的基本例子。这个例子假设你想测试一个网页（比如 Google 主页）的某些功能。我们将使用 **Selenium** 来控制浏览器，**Unittest** 作为测试框架，并使用 **HtmlTestRunner** 来生成测试报告。

- **Selenium**：

  - 一个用于自动化网页测试的工具，可以模拟用户在浏览器中的行为。
  - 支持多种浏览器，包括 Chrome、Firefox 等。

- **Unittest**：

  - Python 的标准库之一，用于编写和运行单元测试。
  - 提供测试框架，支持测试用例的组织、执行和报告。

- **HtmlTestRunner**：

  - 一个 Python 库，用于生成易于阅读的 HTML 测试报告。

  - 作为 Unittest 的一个扩展，可以替换默认的文本测试运行器。

    

- **集成目的**：

  - 使用 Selenium 自动化浏览器操作，实现网页测试。
  - 通过 **Unittest** 构建测试用例和测试套件。
  - 利用 **HtmlTestRunner** 生成测试报告，提供更好的可视化和易读性。

- **测试流程**：

  - 使用 **Selenium** 编写测试脚本，模拟用户行为。

  - 利用 **Unittest** 框架组织测试代码，定义测试用例和断言。

  - 在测试执行结束后，使用 HtmlTestRunner 生成 HTML 格式的报告。

    

在这个脚本中：

- `setUp` 方法初始化浏览器（在这里是 Chrome）。
- `test_search_in_google` 是一个测试案例，它打开 Google 主页，执行一个搜索操作，并验证结果是否正确。
- `tearDown` 方法在测试完成后关闭浏览器窗口。
- 使用 `HtmlTestRunner` 来生成 HTML 格式的测试报告。

运行这个脚本将打开 Chrome，自动执行测试步骤，并在 `example_dir` 目录下生成一个 HTML 测试报告。

```python
import unittest
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import HtmlTestRunner

class GoogleSearchTest(unittest.TestCase):

    def setUp(self):
        # 设置 WebDriver
        self.driver = webdriver.Chrome(executable_path='[ChromeDriver 路径]')

    def test_search_in_google(self):
        driver = self.driver
        driver.get("http://www.google.com")

        # 确保标题包含 "Google"
        self.assertIn("Google", driver.title)

        # 找到搜索框并输入查询
        elem = driver.find_element_by_name("q")
        elem.send_keys("Python")
        elem.send_keys(Keys.RETURN)

        # 检查是否得到了结果
        assert "No results found." not in driver.page_source

    def tearDown(self):
        self.driver.close()

if __name__ == "__main__":
    unittest.main(testRunner=HtmlTestRunner.HTMLTestRunner(output='example_dir'))

```

`tearDown`, `test_search_in_google` 等方法是在 Python 的 `unittest` 测试框架中定义的。这些方法的调用方式和时机是由 `unittest` 框架自动管理的，而不是由开发者直接调用。



### **针对一个用户登录页面的网页，你可以编写那些测试用例？**

**功能测试**

1. **正常登录**：使用有效的用户名和密码进行登录。
2. **无效用户名和/或密码**：使用无效的用户名和密码，应显示错误消息。
3. **空白字段**：不填写用户名或密码或两者都不填写，应显示必填或错误消息。
4. **特殊字符支持**：检查是否可以在用户名和密码中使用特殊字符。
5. **大小写敏感性**：验证用户名和密码是否区分大小写。
6. **忘记密码**：测试忘记密码功能，是否能通过邮箱或手机等方式重置密码。
7. **会话超时**：验证长时间不活动后是否自动登出。

**安全性测试**

1. **SQL注入**：确保应用程序不受SQL注入攻击的影响。

   假设一个简单的登录表单，后端代码用于检索用户信息可能如下：

   ```
   SELECT * FROM users WHERE username = '$username' AND password = '$password';
   ```

   在这里，`$username` 和 `$password` 是用户输入的内容。如果应用程序没有正确地处理这些输入，攻击者可以输入特殊的字符串来操纵SQL查询，例如：

   ```
   Username: admin' --
   Password: (任意值)
   ```

   这将使SQL查询变为：

   ```
   SELECT * FROM users WHERE username = 'admin' --' AND password = '(任意值)';
   ```

   由于 `--` 是SQL中的注释标记，所以查询的其余部分将被注释掉，这意味着只要用户名为 `admin` 的用户存在，查询就会成功，不管密码是否正确。

2. **XSS攻击**：确保没有跨站脚本（XSS）漏洞。

3. **多次错误尝试**：在多次连续错误登录尝试后，应限制用户尝试登录或触发验证码。

4. **数据传输安全**：确保密码和其他敏感信息在网络上传输时是加密的。

5. **密码安全策略**：检查是否实施了强密码策略。



**性能测试**

1. **加载时间**：确保页面在不同网络环境下能快速加载。
2. **并发用户**：测试系统能否在多个用户同时登录的情况下保持稳定。



**用户体验测试**

1. **响应式设计**：确保登录页面在不同大小和类型的设备上都能正常工作。
2. **错误消息**：确保所有错误消息都是清晰和用户友好的。
3. **字段焦点**：在输入错误后，焦点是否会自动移到错误字段。
4. **键盘快捷键**：例如，是否可以使用Enter键提交表单。



### 测试用例设计并讲解：微信发送图片

**功能测试**

1. **基础发送测试**
   - **目的**：验证正常情况下能否成功发送图片。
   - **步骤**：选择一个聊天窗口，点击添加图片的图标，选择一张图片，点击发送。
   - **预期结果**：图片应成功发送并在聊天窗口中显示。
2. **多图发送测试**
   - **目的**：验证是否能同时发送多张图片。
   - **步骤**：在同一个聊天窗口中选择多张图片并发送。
   - **预期结果**：所有选定的图片都应成功发送。
3. **格式支持测试**
   - **目的**：验证支持的图片格式（如 JPEG, PNG, GIF 等）。
   - **步骤**：尝试发送不同格式的图片。
   - **预期结果**：支持的格式应能成功发送，不支持的格式应给出警告。

**性能测试**

1. **大文件发送测试**
   - **目的**：验证大文件（接近或达到微信允许的最大限制）是否能成功发送。
   - **步骤**：选择一张大文件大小的图片尝试发送。
   - **预期结果**：如果在微信允许的大小内，应能成功发送；否则，应有相应的错误提示。
2. **高并发测试**
   - **目的**：模拟多用户同时发送图片的场景。
   - **步骤**：使用测试工具模拟多个用户账号同时发送图片。
   - **预期结果**：图片应成功发送，不应有延迟或失败。

**异常测试**

1. **网络不稳定环境下发送图片**
   - **目的**：测试在网络信号差或不稳定的情况下能否成功发送图片。
   - **步骤**：在网络不稳定的环境下尝试发送图片。
   - **预期结果**：应有合适的处理机制，如重试、提示用户网络不稳定等。
2. **无网络环境下发送图片**
   - **目的**：测试在没有网络的情况下应用的表现。
   - **步骤**：关闭所有网络连接，尝试发送图片。
   - **预期结果**：应提示用户当前无网络，不能发送图片。

**安全性测试**

1. **非法文件测试**

   - **目的**：**验证应用是否能阻止发送包含恶意代码的图片文件。**

   - **步骤**：尝试发送一个包含恶意代码的图片文件。

   - **预期结果**：应阻止发送并给出警告。

     

### 为一个手机上的日历页面设计测试用例

为手机上的日历页面设计测试用例时，你需要确保覆盖各种功能点和可能的使用场景。以下是设计测试用例时可以考虑的几个步骤和方面：

**1. 理解需求和功能**

在开始设计测试用例之前，需要理解应用的需求说明和日历的功能。日历应用可能包括以下功能：

- 显示日期和事件
- 添加、编辑和删除事件
- 设置提醒和重复事件
- 事件的分类和标记
- 同步事件（如与Google日历或其他服务同步）



**2. 确定测试策略**

你需要决定测试的范围和深度，包括：

- **功能测试**
- **界面和用户体验测试**
- **性能测试**
- **安全性测试**
- **兼容性测试（不同设备、操作系统版本等）**



**3. 设计测试用例**

创建详细的测试用例，每个测试用例都应该有一个明确的目标，它们应该包括但不限于：

**功能性测试用例**

- **基本功能**：验证日历的基本显示功能，如月份显示、日期跳转等。
- **事件管理**：添加、修改、删除事件并验证更改。
- **提醒功能**：设置不同类型的提醒并验证它们是否按预期触发。
- **重复事件**：设置重复事件并验证它们的重复模式。
- **搜索功能**：搜索特定事件并验证结果。

**界面和用户体验**

- **布局检查**：确保日历和事件在不同设备和方向（横屏/竖屏）下正确显示。
- **交互性**：各种用户操作（点击、滑动等）响应是否正确。
- **无障碍性**：对于视力受限等用户的无障碍功能测试。

**性能测试**

- **速度**：事件加载和月份切换的速度。
- **资源占用**：应用在运行时占用的内存和CPU。

**安全性测试**

- **数据保护**：验证用户数据是否安全，是否有适当的加密措施。

**兼容性测试**

- **设备兼容性**：在不同的设备和屏幕尺寸上测试。
- **操作系统兼容性**：在不同版本的操作系统上测试。
- **网络兼容性**：在不同网络状况下测试数据同步功能。



### 根据王者荣耀的抽奖池编写测试用例

编写测试用例通常需要根据实际的软件需求文档（Software Requirements Specification, SRS）来完成。但是，我们可以基于抽奖池的一般功能和逻辑来构建一些基础的测试用例。对于王者荣耀这样的游戏，抽奖池可能会包含角色皮肤、英雄、游戏货币等作为奖品。

以下是一些基本的测试用例示例：

**功能性测试用例：**

**测试用例 1：验证抽奖功能是否正常工作**

- **前提条件**：用户账户已登录，并且有足够的抽奖代币或游戏货币。

- 测试步骤

  1. 导航到抽奖页面。
2. 选择一次抽奖。
  3. 确认抽奖消耗的代币或货币。
  4. 观察抽奖结果。

- 预期结果

  - 抽奖动作顺利完成。
- 抽奖代币或货币被正确扣除。
  - 抽奖结果显示在屏幕上，并与账户奖品记录同步更新。

**测试用例 2：验证抽奖结果的随机性**

- **前提条件**：抽奖算法应确保所有奖品的抽取是随机的。

- 测试步骤

  1. 进行大量抽奖操作（例如1000次）。
2. 记录每次抽奖的结果。

- **预期结果**：各个奖品的中奖频率应符合预定义的概率分布。

**测试用例 3：验证抽奖连续操作的响应**

- **前提条件**：用户有足够的代币进行多次抽奖。

- 测试步骤

  1. 选择10次连抽（如果这个功能存在）。
2. 观察和记录抽奖过程和结果。

- 预期结果

  - 抽奖动画和结果顺利显示。
- 账户的代币正确扣除对应数量。
  - 抽到的奖品正确记录在用户账户中。



**性能测试用例：**

**测试用例 4：验证抽奖系统的并发处理能力**

- **前提条件**：模拟多个用户（例如100个）同时进行抽奖操作。

- **测试步骤**
1. 所有模拟用户同时发起抽奖请求。
2. 监控系统的响应时间和服务器资源消耗。

- **预期结果**
- 所有抽奖请求都能在合理时间内得到响应。
- 服务器资源消耗保持在可接受的范围。



**异常处理测试用例：**

**测试用例 5：验证抽奖过程中断的处理**

- **前提条件**：用户已经开始抽奖过程。

- **测试步骤**
1. 在抽奖动画过程中模拟网络中断。
2. 恢复网络连接后检查系统响应。

- **预期结果**
- 抽奖过程能够在网络恢复后继续。
- 如果抽奖已经决定了结果，应保证用户获得奖品。
  - 如果抽奖未能完成，用户不应损失代币或货币。



**安全性测试用例：**

**测试用例 6：验证抽奖系统的抗篡改能力**

- **前提条件**：准备对抽奖系统的通信进行篡改尝试。

- **测试步骤**
1. 尝试修改从客户端发往服务器的抽奖请求数据。
2. 尝试通过**第三方工具修改抽奖结果。**

- **预期结果**
- **服务器能够检测到篡改并拒绝非法请求。**
- 系统应**确保所有抽奖结果都是在服务器端决定。**



**用户体验测试用例：**

**测试用例 7：验证抽奖的用户体验**

- **前提条件**：用户可以正常访问抽奖页面。

- **测试步骤**
1. 用户参与抽奖过程。
2. 用户评价抽奖过程的界面设计、动画效果和易用性。

- **预期结果**

  - 用户报告表示抽奖界面直观易用。

  - 抽奖过程中的动画效果流畅，没有明显延迟。

    

### 设计关于一个游戏boss的测试用例

 游戏新出一个野外Boss,每天19:00-20:00开放，只在场景A和固定的三个位置开放，一共三只Boss.首次伤害的队伍或者队友有奖励，击杀后的队伍或者队友有奖励。击杀过程中其他队伍可协助，但无奖励。每周共享奖励不超过两次。20:00还未击杀Boss,Boss消失。每周日20:00更新Boss奖励。

1. **时间和地点测试**

- **测试用例**：在19:00前后到场景A检查Boss是否按计划出现。
- **测试用例**：在20:00检查Boss是否如期消失。

2. **位置准确性测试**

- **测试用例**：验证Boss是否只在指定的三个位置出现。

3. **首次伤害奖励测试**

- **测试用例**：第一个对Boss造成伤害的队伍或队友是否收到了奖励。
- **测试用例**：确保非首次伤害造成者不会错误地获得首次伤害奖励。

4. **击杀奖励测试**

- **测试用例**：击杀Boss的队伍或队友是否正确获得奖励。
- **测试用例**：测试在不同的击杀方式下（如单人、团队合作）奖励的发放情况。

5. **协助击杀测试**

- **测试用例**：协助击杀但未造成首次伤害的队伍在击杀后是否正确地未获得奖励。

6. **奖励限制测试**

- **测试用例**：确保每个玩家或队伍每周的奖励次数不超过两次。
- **测试用例**：在达到周奖励限制后继续击杀Boss，确认不再获得奖励。

7. **Boss消失行为测试**

- **测试用例**：在20:00时Boss是否正确地从游戏中消失，不论其健康状态如何。

8. **奖励更新测试**

- **测试用例**：每周日20:00后，验证新一周的Boss奖励是否已更新。

9. **边界情况测试**

- **测试用例**：在19:59和20:00的边界时间对Boss进行攻击，测试奖励发放和Boss消失的正确性。

10. **稳定性和性能测试**

- **测试用例**：在Boss战期间检查游戏服务器的性能和稳定性，尤其是在玩家人数众多的情况下。



### 设计游戏角色数值修改后的测试用例

想要改变安琪拉（王者荣耀中的一个英雄）的二技能移速和伤害，应该怎么做测试用例

1. **基础功能测试**
   - **测试用例 1.1**：验证修改后的二技能是否能正确激活和使用。
   - **测试用例 1.2**：测试技能的基本操作，如施放距离、方向控制是否正常。
2. **移动速度测试**
   - **测试用例 2.1**：测量使用二技能后安琪拉的移动速度，确保它符合预期的数值。
   - **测试用例 2.2**：比较修改前后的移动速度，评估速度变化对游戏平衡的影响。
3. **伤害输出测试**
   - **测试用例 3.1**：测量技能对敌方英雄、小兵和野怪造成的伤害，确保它与预期数值相符。
   - **测试用例 3.2**：在不同的游戏阶段（游戏初期、中期和后期）测试技能的伤害输出，评估其在游戏进程中的效果。
4. **技能交互测试**
   - **测试用例 4.1**：测试技能与安琪拉的其他技能的交互，确保没有出现意外的行为或效果。
   - **测试用例 4.2**：测试技能与其他英雄的技能交互，比如技能抵消、技能增强等。
5. **游戏平衡测试**
   - **测试用例 5.1**：在实战中测试技能的效果，观察其对单挑、团战等场景的影响。
   - **测试用例 5.2**：评估改变后的技能是否对某些对局或游戏策略产生了过强或过弱的影响。
6. **稳定性和性能测试**
   - **测试用例 6.1**：在不同的游戏设备和网络环境下测试技能的稳定性。
   - **测试用例 6.2**：监控使用技能时的游戏性能，如帧率、响应时间等。
7. **用户体验测试**
   - **测试用例 7.1**：收集玩家对于改变后技能的反馈，包括满意度、易用性等。
   - **测试用例 7.2**：评估技能修改对新手和资深玩家的影响，确保技能对所有技能水平的玩家都公平。



### 请问如果我希望测试原神里一个新出的角色，请问可能从什么角度进行测试？

1. **角色属性与技能**：
   - **基本属性**：检查角色的生命值、攻击力、防御力等基础属性。
   - **元素属性**：了解角色的元素属性（如风、火、水、雷等）及其互动方式。
   - **技能和爆发**：测试角色的主动技能和元素爆发的效果、冷却时间、消耗等。
2. **战斗表现**：
   - **单体与群体伤害**：测试角色对单个敌人和多个敌人的伤害输出。
   - **元素反应**：观察角色的元素技能与其他元素的反应效果。
   - **支援能力**：评估角色在团队中的支援能力，如治疗、增益或减益效果。
3. **装备与构建**：
   - **武器选择**：测试不同类型的武器对角色表现的影响。
   - **圣遗物搭配**：尝试不同的圣遗物套装，看哪种搭配最适合该角色的技能和战斗风格。
4. **可玩性与操作**：
   - **操作感受**：评估角色的操作难易程度、移动速度、攻击流畅度等。
   - **角色定位**：根据角色的技能和属性，确定其在团队中的最佳定位（如主DPS、辅助、治疗等）。
5. **与其他角色的协同**：
   - **团队配合**：测试该角色与不同角色组合时的协同效果。
   - **元素搭配**：探究不同元素组合在实战中的效果。
6. **特殊环境适应性**：
   - **不同场景**：在**不同的游戏环境（如不同的敌人类型、地形）中测试角色的适应性和效能。**





![image-20231020142819415](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020142819415.png)



A. **`@Test`注解标注的测试方法只能是 `public void` 的，且不能有任何输入参数**

- 这是正确的。使用 `@Test` 注解标注的测试方法必须是 `public void` 类型，并且不能有输入参数。

B. **`AssertEquals`、`AssertNotEquals`：判断两个对象是否为同一个**

- 这是不正确的。`assertEquals` 用于检查两个对象是否相等（即调用 `.equals()` 方法的结果），而不是检查是否为同一个对象（即通过 `==` 操作符检查）。`assertNotEquals` 则用于检查两个对象是否不相等。

C. **`@BeforeClass`注解每一个测试方法都要执行一次，且必须为 `static void`**

- 这是不正确的。`@BeforeClass` 注解标注的方法在该测试类的所有测试方法执行前只执行一次，而不是每一个测试方法执行前都执行。此外，这个方法必须是 `static void`。

![image-20231020135518141](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020135518141.png)

   工作说明书/需求规格说明书—SOW 制定测试的进度  

   概要设计说明书-HLD 设计测试的用例  

   详细设计说明书-LLD 程序员编码实现  

   单元测试用例-UTC  单元测试使用  



![image-20231020135751807](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020135751807.png)

无效等价类是指对于软件规格说明而言，是没有意义的、不合理的输入数据集合。



![image-20231020140004148](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020140004148.png)

 (1)所有的测试都应追溯到用户需求。

 (2)应当把“尽早地和不断地进行软件测试”作为座右铭。

 (3)pareto原则：测试发现的错误中80%很可能起源于20%的模块中。  

 (4)完全测试是不可能的，测试需要终止。  

 (5)应由独立的第三方来构造测试。 

 (6)充分注意测试中的群集现象。

 (7)尽量避免测试的随意性。  

 (8)兼顾合理的输入和不合理的输入数据。

 (9)程序修改后要回归测试。

 (10)应长期保留用例，直至系统废弃。



![image-20231020140346592](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020140346592.png)





![image-20231020140748992](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020140748992.png)

A. 并发用户数：这不是疲劳强度测试主要关注的问题。这更多地与性能测试和负载测试有关。

**B. 内存泄漏：这是疲劳强度测试最可能首先发现的问题。长时间的运行可能会暴露内存泄漏问题。**

C. 系统安全性：疲劳强度测试通常不聚焦**于系统的安全性问题。**

D. 功能错误：虽然长时间的运行可能会触发某些功能错误，但这并不是疲劳强度测试的主要关注点。



![image-20231020140837318](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020140837318.png)

一般来说，集成测试计划不会在需求分析阶段末提交。集成测试是在多个单元或组件已经分别进行了单元测试之后，将它们集成到一个更大的系统或子系统中时进行的测试。因此，集成测试通常是在单元测试之后进行的，也就是在编码和单元测试阶段之后。集成测试计划通常会在详细设计阶段完成或编码阶段开始时准备。

在软件开发的生命周期中，需求分析阶段主要关注于明确客户和系统的需求，而不是关注软件的测试活动。测试活动通常在稍后的阶段更为明确和活跃，尤其是在设计和编码阶段完成之后。



![image-20231020141144427](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020141144427.png)

 **单元测试工具集合:** 

  **Parasoft jtest** 

  第一个自动化Java单元**测试**工具. 

  **Parasoft C++Test** 

  是**单元测试**和静态分析工具，自动测试C和C＋＋类别、功能或组件. 

  **Parasoft .TEST** 

  **是单元测试和静态分析工具，自动测试写在Microsoft?.NET框架的类别** 

  **Parasoft Insure++** 

  是一个自动化的内存错误、内存泄漏的精确检测工具。 

  **Parasoft CodeWizard** 

  是高级C/C++源代码分析工具，采用三百种以上行业相关的编码准则，自动识别编译器未检测到的危险的编码构造。 

  **DevPartner Studio Professional** 

  是针对软件开发小组使用 Microsoft Visual C++，Microsoft Visual Basic，Java,ASP 或 HTML 设计的一套紧密配合的调试，测试和管理工具。 

  **Rational Purify** 

  是一个面向VC, VB或者Java开发的测试Visual C/C++ 和Java代码中与内存有关的错误，确保整个应用程序的质量和可靠性。 

  **Rational Quantify** 

  是一个面向VC、VB 或者Java开发的测试性能瓶颈检测工具 

  **Rational PureCoverage** 

  是一个面向VC、VB或者Java开发的测试覆盖程度检测工具 





![image-20231020141747127](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020141747127.png)

4个，case0，case1，case2和3，default

语句覆盖是指选择足够多的测试数据，使被测程序中的每条语句至少执行一次。0，1，2，3一共四条语句即可，因为在执行2，3时无break，所以default语句也将被执行。 



![image-20231020141920907](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020141920907.png)

在项目的早期阶段就开始设计系统测试用例，因为这样更容易发现问题，并且给予更多的时间来解决这些问题。所以，如果要选择最佳的时间开始设计测试用例，**需求完成（选项A）**通常被认为是最适当的，尤其是在敏捷或迭代的开发环境中。然而，在更传统的瀑布模型中，可能会选择在**详细设计完成（选项B）**后开始。




![image-20231020142218237](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020142218237.png)



![image-20231020142517483](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020142517483.png)

比较判断与控制流常常紧密相关，测试时注意下列错误： 

1. 不同数据类型的对象之间进行比较;  2. 错误地使用逻辑运算符或优先级;  3. 因计算机表示的局限性，期望理论上相等而实际上不相等的两个量相等;  4. 比较运算或变量出错;  5. 循环终止条件或不可能出现;  6. 迭代发散时不能退出;  7. 错误地修改了循环变量。 



![image-20231020143228307](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020143228307.png)

因果图法着重测试规格说明中的输入与输出间的依赖关系。

  等价类划分法和边界值分析方法都是着重考虑输入条件，但没有考虑输入条件的各种组合、输入条件之间的相互制约关系。这样虽然各种输入条件可能出错的情况已经测试到了，但多个输入条件组合起来可能出错的情况却被忽视了。 

 如果在测试时必须考虑输入条件的各种组合，则可能的组合数目将是天文数字，因此必须考虑采用一种适合于描述多种条件的组合、相应产生多个动作的形式来进行测试用例的设计，这就需要利用因果图（逻辑模型）。



![image-20231020143505803](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020143505803.png)

【软件需求】是软件开发之前做好的，软件开发是根据这个做的，那么软件测试自然也需要参考该文件 【迭代计划】是软件的某个周期的计划，自然也需要参考 【可行性】是软件开发前做好，用于证明该计划可行的，没有必要参考 



![image-20231020143918748](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020143918748.png)

性能测试、压力测试、负载测试的关系

- 性能测试是正常情况下的性能指标； (选择时间)
- 压力测试是测试系统的瓶颈所在； 
- 负载测试是指系统重负荷性能指标; 



![image-20231020153010638](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020153010638.png)

这种策略是一种“非增量集成测试”（Non-incremental Integration Testing）。在非增量集成测试中，各个模块独立地进行测试，然后所有模块一起集成，执行一个集成测试，而不是逐步地、增量地添加模块进行测试。

增量集成测试（Incremental Integration Testing）是指逐步添加模块并进行测试，而不是一次性集成所有模块。

三明治集成测试（Sandwich Integration Testing）是一种结合了自顶向下和自底向上集成测试的方法，这里没有提到这种情况。

![image-20231020153101436](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020153101436.png)

LoadRunner-负载压力测试：预测系统性能。

 JMeter+Badboy：基于JAVA的压力测试工具，Badboy用来进行脚本的录制 

功能测试：通过自动录制、检测和回放用户的应用操作。将输出记录同预先给定的记录比较。 

Junit：白盒测试工具：针对代码测试 测试管理工具：对测试需求、计划、用例、实施进行管理 

测试辅助工具：本身不执行，可以生成测试数据，为测试提供数据准备 

负载压力测试：LoadRunner:预测系统行为和性能的工业标准级负载测试工具。模拟上千万用户同时实施并发操作，来实时监控可能发生的问题。 

功能测试： QTP(quicktest professional):自动测试工具 

白盒测试：C++ TEST（做C和C++的白盒测试）、JUnit（Java白盒测试） 

缺陷管理工具：Mantis、BugFree、QC、TD 

用例管理工具：TestLink、QC 测试辅助工具：SVN



![image-20231020153553708](C:\Users\hongj\AppData\Roaming\Typora\typora-user-images\image-20231020153553708.png)

在自底向上集成测试（Bottom-up Integration Testing）中，测试通常从最底层的模块（也就是没有依赖的模块）开始，然后逐渐向上集成更高层次的模块。由于最底层的模块通常被上层模块调用，因此在它们单独存在时，需要一个“驱动程序”（Driver）来模拟上层模块的行为，以便能够执行测试。

驱动程序负责初始化测试环境，调用下层模块，并接收这些模块返回的数据，以检查其是否正常工作。因此，测试员确实需要编写驱动程序来进行自底向上的集成测试。

